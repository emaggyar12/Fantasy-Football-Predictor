{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import requests\n",
    "import ssl\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining years\n",
    "\n",
    "years = []\n",
    "urls = []\n",
    "\n",
    "for i in range(2016, 2024):\n",
    "    years.append(i)\n",
    "\n",
    "teams_df = pd.read_csv('clustered_df.csv')\n",
    "\n",
    "teams_upper = []\n",
    "teams_lower = []\n",
    "\n",
    "for i in range(len(teams_df)):\n",
    "    team = teams_df.loc[i, \"team\"]\n",
    "    if team not in teams_upper:\n",
    "        teams_upper.append(team)\n",
    "\n",
    "for i in range(len(teams_upper)):\n",
    "    teams_lower.append(teams_upper[i].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all team hrefs from the website\n",
    "\n",
    "url = \"https://www.pro-football-reference.com/years/2023/#all_team_stats\"\n",
    "\n",
    "# Sending a GET request to fetch the page content\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Parsing the page content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Finding all of the links\n",
    "anchors = soup.find_all('a', href=True)\n",
    "href_list = [anchor['href'] for anchor in anchors]\n",
    "\n",
    "# Adding all relevant hrefs to a list\n",
    "team_hrefs = []\n",
    "\n",
    "for href in href_list:\n",
    "    if '/teams/' in href:\n",
    "        if href not in team_hrefs:\n",
    "            team_hrefs.append(href)\n",
    "\n",
    "team_hrefs = team_hrefs[1:]\n",
    "\n",
    "team_hrefs = [href.replace('.htm', '') for href in team_hrefs]\n",
    "team_hrefs = [href.rsplit('/', 1)[0] for href in team_hrefs]\n",
    "\n",
    "team_hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making team abbreviation csv to make indexing easier\n",
    "\n",
    "teams_abbreviation = pd.read_csv('teams_abbreviations.csv')\n",
    "teams_abbreviation['Lower'] = teams_lower\n",
    "teams_abbreviation['Upper'] = teams_upper\n",
    "\n",
    "reference_abbreviations = []\n",
    "reference_abbreviations = [reference.split('/')[-1] for reference in team_hrefs]\n",
    "\n",
    "for r in range(len(teams_abbreviation)):\n",
    "    lowercase = teams_abbreviation.loc[r, 'Lower']\n",
    "    if lowercase in reference_abbreviations:\n",
    "        index = reference_abbreviations.index(lowercase)\n",
    "        teams_abbreviation.loc[r, 'Reference'] = reference_abbreviations[index]\n",
    "\n",
    "teams_abbreviation.loc[0, 'Reference'] = 'crd'\n",
    "teams_abbreviation.loc[2, 'Reference'] = 'rav'\n",
    "teams_abbreviation.loc[11, 'Reference'] = 'gnb'\n",
    "teams_abbreviation.loc[12, 'Reference'] = 'htx'\n",
    "teams_abbreviation.loc[13, 'Reference'] = 'clt'\n",
    "teams_abbreviation.loc[15, 'Reference'] = 'kan'\n",
    "teams_abbreviation.loc[16, 'Reference'] = 'ram'\n",
    "teams_abbreviation.loc[17, 'Reference'] = 'sdg'\n",
    "teams_abbreviation.loc[18, 'Reference'] = 'rai'\n",
    "teams_abbreviation.loc[21, 'Reference'] = 'nwe'\n",
    "teams_abbreviation.loc[22, 'Reference'] = 'nor'\n",
    "teams_abbreviation.loc[28, 'Reference'] = 'sfo'\n",
    "teams_abbreviation.loc[29, 'Reference'] = 'tam'\n",
    "teams_abbreviation.loc[30, 'Reference'] = 'oti'\n",
    "\n",
    "teams_abbreviation.to_csv('teams_abbreviations.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping single-season statistics for each quarterback for each team and creating new .csv for each position\n",
    "\n",
    "for num in range(0, 32):\n",
    "    team = team_hrefs[num]\n",
    "    \n",
    "    # URL to scrape\n",
    "    url = f\"https://www.pro-football-reference.com/{team}/\"\n",
    "\n",
    "    # Sending a GET request to fetch the page content\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Parsing the page content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Finding all of the links\n",
    "    anchors = soup.find_all('a', href=True)\n",
    "    href_list = [anchor['href'] for anchor in anchors]\n",
    "\n",
    "    # Adding all relevant hrefs to a list\n",
    "    relevant_hrefs = []\n",
    "\n",
    "    for year in years:\n",
    "        if f'{team}/{year}.htm' in href_list:\n",
    "            index = href_list.index(f'{team}/{year}.htm')\n",
    "            for j in range(index, index + 9):\n",
    "                relevant_hrefs.append(href_list[j])\n",
    "\n",
    "    relevant_hrefs = [href.replace('.htm', '') for href in relevant_hrefs]\n",
    "\n",
    "    qb_years = []\n",
    "\n",
    "    l = 0\n",
    "        \n",
    "    for j, year in enumerate(years):\n",
    "        qb_data = []\n",
    "\n",
    "        link = f'{team}/{year}'\n",
    "        index = relevant_hrefs.index(link)\n",
    "\n",
    "        # EDIT SEQUENCE OF HREFS IF COACH WAS FIRED DURING A SEASON\n",
    "\n",
    "        # ONLY FOR THE BROWNS\n",
    "        if num == 6:\n",
    "            if year == 2018:\n",
    "                qb_href = relevant_hrefs[index + 7]\n",
    "            else:\n",
    "                qb_href = relevant_hrefs[index + 6]\n",
    "\n",
    "        # ONLY FOR THE TEXANS\n",
    "        elif num == 9:\n",
    "            if year == 2020:\n",
    "                qb_href = relevant_hrefs[index + 7]\n",
    "            else:\n",
    "                qb_href = relevant_hrefs[index + 6]\n",
    "\n",
    "        # ONLY FOR THE JAGUARS\n",
    "        elif num == 10:\n",
    "            if year == 2016 or year == 2021:\n",
    "                qb_href = relevant_hrefs[index + 7]\n",
    "            else:\n",
    "                qb_href = relevant_hrefs[index + 6]\n",
    "        \n",
    "        # ONLY FOR THE COLTS\n",
    "        elif num == 11:\n",
    "            if year == 2022:\n",
    "                qb_href = relevant_hrefs[index + 7]\n",
    "            else:\n",
    "                qb_href = relevant_hrefs[index + 6]\n",
    "\n",
    "        # ONLY FOR THE RAIDERS\n",
    "        elif num == 13:\n",
    "            if year == 2021 or year == 2023:\n",
    "                qb_href = relevant_hrefs[index + 7]\n",
    "            else:\n",
    "                qb_href = relevant_hrefs[index + 6]\n",
    "\n",
    "        # ONLY FOR THE BRONCOS\n",
    "        elif num == 14:\n",
    "            if year == 2022:\n",
    "                qb_href = relevant_hrefs[index + 7]\n",
    "            else:\n",
    "                qb_href = relevant_hrefs[index + 6]\n",
    "\n",
    "        # ONLY FOR THE CHARGERS\n",
    "        elif num == 15:\n",
    "            if year == 2023:\n",
    "                qb_href = relevant_hrefs[index + 7]\n",
    "            else:\n",
    "                qb_href = relevant_hrefs[index + 6]\n",
    "\n",
    "        # ONLY FOR THE GIANTS:\n",
    "        elif num == 18:\n",
    "            if year == 2017:\n",
    "                qb_href = relevant_hrefs[index + 7]\n",
    "            else:\n",
    "                qb_href = relevant_hrefs[index + 6]\n",
    "\n",
    "        # ONLY FOR THE COMMANDERS:\n",
    "        elif num == 19:\n",
    "            if year == 2019:\n",
    "                qb_href = relevant_hrefs[index + 7]\n",
    "            else:\n",
    "                qb_href = relevant_hrefs[index + 6]\n",
    "\n",
    "        # ONLY FOR THE LIONS:\n",
    "        elif num == 20:\n",
    "            if year == 2020:\n",
    "                qb_href = relevant_hrefs[index + 7]\n",
    "            else:\n",
    "                qb_href = relevant_hrefs[index + 6]\n",
    "\n",
    "        # ONLY FOR THE PACKERS:\n",
    "        elif num == 21:\n",
    "            if year == 2018:\n",
    "                qb_href = relevant_hrefs[index + 7]\n",
    "            else:\n",
    "                qb_href = relevant_hrefs[index + 6]\n",
    "\n",
    "        # ONLY FOR THE FALCONS:\n",
    "        elif num == 26:\n",
    "            if year == 2020:\n",
    "                qb_href = relevant_hrefs[index + 7]\n",
    "            else:\n",
    "                qb_href = relevant_hrefs[index + 6]\n",
    "\n",
    "        # ONLY FOR THE PANTHERS:\n",
    "        elif num == 27:\n",
    "            if year == 2019 or year == 2022 or year == 2023:\n",
    "                qb_href = relevant_hrefs[index + 7]\n",
    "            else:\n",
    "                qb_href = relevant_hrefs[index + 6]\n",
    "\n",
    "        # ONLY FOR THE RAMS:\n",
    "        elif num == 29:\n",
    "            if year == 2016:\n",
    "                qb_href = relevant_hrefs[index + 7]\n",
    "            else:\n",
    "                qb_href = relevant_hrefs[index + 6]\n",
    "\n",
    "        # ACTUAL:\n",
    "        else:\n",
    "            qb_href = relevant_hrefs[index + 6]\n",
    "\n",
    "        # Scraping QB base url that includes basic stats\n",
    "        qb_base_url = f'https://www.pro-football-reference.com{qb_href}.htm'\n",
    "\n",
    "        response = requests.get(qb_base_url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        table = soup.find('table')\n",
    "\n",
    "        qb_base_df = pd.read_html(str(table))[0]\n",
    "\n",
    "        qb_base_df = qb_base_df.iloc[:-1]\n",
    "\n",
    "        all_abbreviations = pd.read_csv('teams_abbreviations.csv')\n",
    "        all_reference_abbreviation = all_abbreviations['Reference'].tolist()\n",
    "        all_lower_abbreviation = all_abbreviations['Lower'].tolist()\n",
    "        all_main_upper_abbreviation = all_abbreviations['Upper_Reference'].tolist()\n",
    "        all_backup_upper_abbreviation = all_abbreviations['Backup_Upper_Reference'].tolist()\n",
    "\n",
    "        team_name = team.split('/')[-1]\n",
    "        index = all_reference_abbreviation.index(team_name)\n",
    "\n",
    "        if num == 13:\n",
    "            if year in range(2016, 2020):\n",
    "                upper_name = all_backup_upper_abbreviation[index]\n",
    "            else:\n",
    "                upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "        elif num == 15:\n",
    "            if year == 2016:\n",
    "                upper_name = all_backup_upper_abbreviation[index]\n",
    "            else:\n",
    "                upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "        else:\n",
    "            upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "        number_teams = 0\n",
    "\n",
    "        for i in range(len(qb_base_df)):\n",
    "            year_value = qb_base_df.loc[i, 'Year']\n",
    "            \n",
    "            if pd.notna(year_value):  # Check if the value is not NaN\n",
    "                qb_base_df.loc[i, 'Year'] = str(year_value)[:4]\n",
    "                df_year = int(qb_base_df.loc[i, 'Year'])\n",
    "\n",
    "                if df_year == year:\n",
    "                    df_year_index = i\n",
    "                    teams = str(qb_base_df.loc[i, 'Tm'])\n",
    "                    team_team = teams[1:]\n",
    "\n",
    "                    if team_team == 'TM':\n",
    "                        team_number = int(teams[0])\n",
    "                        number_teams = team_number\n",
    "                        for x in range(1, team_number + 1):\n",
    "                            if str(qb_base_df.loc[i + x, 'Tm']) == upper_name:\n",
    "                                team_proper_index = i + x\n",
    "                                qb_base_df.iloc[df_year_index, 2:] = qb_base_df.iloc[team_proper_index, 2:]\n",
    "                                break\n",
    "                        break\n",
    "                    else:\n",
    "                        qb_base_df = qb_base_df.loc[[i]]\n",
    "                        break\n",
    "        \n",
    "        qb_base_df = qb_base_df.reset_index(drop=True)\n",
    "\n",
    "        for i in range(len(qb_base_df)):\n",
    "            year_value = qb_base_df.loc[i, 'Year']\n",
    "            \n",
    "            if pd.notna(year_value):  # Check if the value is not NaN\n",
    "                qb_base_df.loc[i, 'Year'] = str(year_value)[:4]\n",
    "                df_year = int(qb_base_df.loc[i, 'Year'])\n",
    "\n",
    "                if df_year == year:\n",
    "                    qb_base_df = qb_base_df.loc[[i]]\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'QBrec', 'Lng', 'Y/A', 'AY/A', 'Y/C', 'Yds.1', 'NY/A', 'ANY/A', '4QC', 'GWD', 'AV', 'Awards', 'Y/G']\n",
    "        try:\n",
    "            qb_base_df = qb_base_df.drop(columns = columns_to_drop, axis = 1)\n",
    "        except KeyError:\n",
    "            # 'Awards' not in columns, remove 'Awards' from the list and drop again\n",
    "            columns_to_drop.remove('Awards')\n",
    "            qb_base_df = qb_base_df.drop(columns = columns_to_drop, axis = 1)\n",
    "\n",
    "        qb_base_columns = qb_base_df.columns.tolist()\n",
    "        qb_base_columns[4] = 'Pass_Att'\n",
    "        qb_base_columns[6] = 'Pass_Yds'\n",
    "        qb_base_columns[7] = 'Pass_TD'\n",
    "        qb_base_columns[11] = '1D_Passing'\n",
    "        qb_base_columns[12] = 'Pass_Succ%'\n",
    "        qb_base_df.columns = qb_base_columns\n",
    "\n",
    "        qb_base_df = qb_base_df.reset_index(drop=True)\n",
    "\n",
    "        qb_data.append(qb_base_df)\n",
    "\n",
    "        # Scraping QB Rushing stats\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        url = f'https://www.pro-football-reference.com{qb_href}.htm#all_rushing_and_receiving'\n",
    "\n",
    "        # Send a GET request to the webpage\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the specific table by its ID\n",
    "        table = soup.find('table', {'id': 'rushing_and_receiving'})\n",
    "\n",
    "        # Read the HTML table into a pandas DataFrame\n",
    "        qb_rushing_df = pd.read_html(str(table))[0]\n",
    "\n",
    "        qb_rushing_df.columns = qb_rushing_df.columns.droplevel()\n",
    "\n",
    "        for i in range(len(qb_rushing_df)):\n",
    "            year_value = qb_rushing_df.loc[i, 'Year']\n",
    "            \n",
    "            if pd.notna(year_value):  # Check if the value is not NaN\n",
    "                qb_rushing_df.loc[i, 'Year'] = str(year_value)[:4]\n",
    "                df_year = int(qb_rushing_df.loc[i, 'Year'])\n",
    "\n",
    "                if df_year == year:\n",
    "                    df_year_index = i\n",
    "                    teams = str(qb_rushing_df.loc[i, 'Tm'])\n",
    "                    team_team = teams[1:]\n",
    "\n",
    "                    if team_team == 'TM':\n",
    "                        team_number = int(teams[0])\n",
    "                        number_teams = team_number\n",
    "                        for x in range(1, team_number + 1):\n",
    "                            if str(qb_rushing_df.loc[i + x, 'Tm']) == upper_name:\n",
    "                                team_proper_index = i + x\n",
    "                                qb_rushing_df.iloc[df_year_index, 2:] = qb_rushing_df.iloc[team_proper_index, 2:]\n",
    "                                break\n",
    "                        break\n",
    "                    else:\n",
    "                        qb_rushing_df = qb_rushing_df.loc[[i]]\n",
    "                        break\n",
    "        \n",
    "        qb_rushing_df = qb_rushing_df.reset_index(drop=True)\n",
    "\n",
    "        for i in range(len(qb_rushing_df)):\n",
    "            year_value = qb_rushing_df.loc[i, 'Year']\n",
    "            \n",
    "            if pd.notna(year_value):  # Check if the value is not NaN\n",
    "                qb_rushing_df.loc[i, 'Year'] = str(year_value)[:4]\n",
    "                df_year = int(qb_rushing_df.loc[i, 'Year'])\n",
    "\n",
    "                if df_year == year:\n",
    "                    qb_rushing_df = qb_rushing_df.loc[[i]]\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        qb_rushing_columns = qb_rushing_df.columns.tolist()\n",
    "        qb_rushing_columns[7] = 'Qb_Rush_Att'\n",
    "        qb_rushing_columns[8] = 'Qb_Rush_Yds'\n",
    "        qb_rushing_columns[9] = 'Qb_Rush_Td'\n",
    "        qb_rushing_columns[10] = 'Qb_Rush_1D'\n",
    "        qb_rushing_columns[11] = 'Qb_Rush_Succ%'\n",
    "        qb_rushing_columns[28] = 'Qb_Touches'\n",
    "        qb_rushing_columns[32] = 'Qb_Fmb'\n",
    "        qb_rushing_df.columns = qb_rushing_columns\n",
    "\n",
    "        drop_columns = [0, 1, 2, 3, 4, 5, 6, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31]\n",
    "        qb_rushing_df = qb_rushing_df.drop(qb_rushing_df.columns[drop_columns], axis = 1)\n",
    "\n",
    "        qb_rushing_df = qb_rushing_df.reset_index(drop=True)\n",
    "\n",
    "        qb_data.append(qb_rushing_df)\n",
    "\n",
    "        # Scraping QB fantasy stats\n",
    "        qb_fantasy_url = f\"https://www.pro-football-reference.com{qb_href}/fantasy/\"\n",
    "\n",
    "        response = requests.get(qb_fantasy_url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        table = soup.find('table')\n",
    "\n",
    "        qb_fantasy_df = pd.read_html(str(table))[0]\n",
    "\n",
    "        # TRYING NEW METHOD FOR FANTASY\n",
    "\n",
    "        qb_fantasy_df.columns = qb_fantasy_df.columns.droplevel()\n",
    "        qb_fantasy_df.columns = qb_fantasy_df.columns.droplevel()\n",
    "\n",
    "        qb_fantasy_df = qb_fantasy_df.reset_index(drop=True)\n",
    "\n",
    "        qb_fantasy_df = qb_fantasy_df.fillna(0)\n",
    "\n",
    "        qb_fantasy_df_columns = qb_fantasy_df.columns.tolist()\n",
    "        qb_fantasy_df_columns[0] = 'Year'\n",
    "        qb_fantasy_df.columns = qb_fantasy_df_columns\n",
    "\n",
    "        for i in range(len(qb_fantasy_df)):\n",
    "            year_value = qb_fantasy_df.loc[i, 'Year']\n",
    "            \n",
    "            if pd.notna(year_value):  # Check if the value is not NaN\n",
    "                qb_fantasy_df.loc[i, 'Year'] = str(year_value)[:4]\n",
    "                df_year = int(qb_fantasy_df.loc[i, 'Year'])\n",
    "\n",
    "                if df_year == year:\n",
    "                    df_year_index = i\n",
    "                    teams = str(qb_fantasy_df.loc[i, 'Tm'])\n",
    "                    team_team = teams[1:]\n",
    "\n",
    "                    for x in range(1, number_teams + 1):\n",
    "                        if str(qb_fantasy_df.loc[i + x, 'Tm']) == upper_name:\n",
    "                            team_proper_index = i + x\n",
    "                            qb_fantasy_df.iloc[df_year_index, 1:] = qb_fantasy_df.iloc[team_proper_index, 1:]\n",
    "                            break\n",
    "                        else:\n",
    "                            qb_fantasy_df = qb_fantasy_df.loc[[i]]\n",
    "                            break\n",
    "                    break\n",
    "\n",
    "        qb_fantasy_df = qb_fantasy_df.reset_index(drop=True)\n",
    "\n",
    "        for i in range(len(qb_fantasy_df)):\n",
    "            year_value = qb_fantasy_df.loc[i, 'Year']\n",
    "            \n",
    "            if pd.notna(year_value):  # Check if the value is not NaN\n",
    "                qb_fantasy_df.loc[i, 'Year'] = str(year_value)[:4]\n",
    "                df_year = int(qb_fantasy_df.loc[i, 'Year'])\n",
    "\n",
    "                if df_year == year:\n",
    "                    qb_fantasy_df = qb_fantasy_df.loc[[i]]\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        qb_fantasy_df = qb_fantasy_df.iloc[:, [-9, -4]]\n",
    "\n",
    "        qb_fantasy_df = qb_fantasy_df.reset_index(drop=True)\n",
    "\n",
    "        qb_fantasy_df_columns = qb_fantasy_df.columns.tolist()\n",
    "        qb_fantasy_df_columns[0] = 'Qb_Snap_Percentage'\n",
    "        qb_fantasy_df_columns[1] = 'Qb_FantPt'\n",
    "        qb_fantasy_df.columns = qb_fantasy_df_columns\n",
    "\n",
    "        qb_snap_percentage = qb_fantasy_df.loc[0, 'Qb_Snap_Percentage']\n",
    "\n",
    "        qb_snap_percentage = qb_snap_percentage.replace('%', '')\n",
    "        percentage_float = float(qb_snap_percentage)\n",
    "        decimal_value = percentage_float / 100\n",
    "\n",
    "        qb_fantasy_df.loc[0, 'Qb_Snap_Percentage'] = decimal_value\n",
    "\n",
    "        qb_fantasy_df = qb_fantasy_df.reset_index(drop=True)\n",
    "\n",
    "        qb_data.append(qb_fantasy_df)\n",
    "\n",
    "        qb_df = pd.concat(qb_data, axis = 1)\n",
    "\n",
    "        # Convering the statsitics to per-game\n",
    "        per_game_stats = ['Cmp', 'Pass_Att', 'Pass_TD', 'Pass_Yds', 'Int', '1D_Passing', 'Sk', 'Qb_Rush_Att', 'Qb_Rush_Yds', 'Qb_Rush_Td', 'Qb_Rush_1D', 'Qb_Touches', 'Qb_Fmb', 'Qb_FantPt']\n",
    "\n",
    "        games = int(qb_df.loc[:, 'G'])\n",
    "        for stat in per_game_stats:\n",
    "            qb_df.loc[:, stat] = float(qb_df.loc[:, stat]) / games\n",
    "\n",
    "        qb_df = qb_df.iloc[:, 1:]\n",
    "\n",
    "        qb_df = qb_df.reset_index(drop=True)\n",
    "\n",
    "        qb_df_columns = qb_df.columns.tolist()\n",
    "        qb_df_columns[0] = 'Qb_Age'\n",
    "        qb_df_columns[1] = 'Qb_G'\n",
    "        qb_df_columns[7] = 'Qb_TD%'\n",
    "        qb_df.columns = qb_df_columns\n",
    "\n",
    "        full_clustered_df = pd.read_csv('clustered_df.csv')\n",
    "        all_abbreviations = pd.read_csv('teams_abbreviations.csv')\n",
    "        all_reference_abbreviation = all_abbreviations['Reference'].tolist()\n",
    "        all_lower_abbreviation = all_abbreviations['Lower'].tolist()\n",
    "        all_upper_abbreviation = all_abbreviations['Upper'].tolist()\n",
    "\n",
    "        for r in range(len(full_clustered_df)):\n",
    "            cluster_team_name = full_clustered_df.loc[r, 'team']\n",
    "            team_name = team.split('/')[-1]\n",
    "            season = full_clustered_df.loc[r, 'season']\n",
    "            qb_position = full_clustered_df.loc[r, 'QB_Position']\n",
    "            index = all_reference_abbreviation.index(team_name)\n",
    "            upper_name = all_upper_abbreviation[index]\n",
    "\n",
    "            quart = qb_df.columns.tolist()\n",
    "\n",
    "            if cluster_team_name == upper_name:\n",
    "                if season == year:\n",
    "                    if qb_position == 1:\n",
    "                        qb_df = qb_df.rename(index={qb_df.index[0]: r})\n",
    "                        row_index = qb_df.index[0]\n",
    "                        for col in quart:\n",
    "                            full_clustered_df.loc[r, col] = qb_df.loc[row_index, col]\n",
    "                        \n",
    "        \n",
    "        full_clustered_df.to_csv('clustered_df_qb.csv', index  = False)\n",
    "        qb_years.append(qb_df)\n",
    "        print(f\"{year} quarterback scraped for {team}.\")\n",
    "\n",
    "        # Remove following break statement to do all years of a franchise\n",
    "        # break\n",
    "    # Remove following break statement to do all franchises\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRAPING CAREER AVERAGES FOR A PLAYER FOR A TEAM'S SEASON\n",
    "\n",
    "for num in range(0, 32):\n",
    "    team = team_hrefs[num]\n",
    "\n",
    "    for j, year in enumerate(years):\n",
    "        url = f'https://www.pro-football-reference.com{team}/{year}-snap-counts.htm'\n",
    "\n",
    "        # Send a request to the website\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check for request errors\n",
    "\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the first table\n",
    "        table = soup.find('table', {'id': 'snap_counts'})\n",
    "\n",
    "        # Extract table headers\n",
    "        headers = [th.getText() for th in table.find('thead').findAll('th')]\n",
    "        rows = table.find('tbody').findAll('tr')\n",
    "\n",
    "        hrefs = []\n",
    "        for row in rows:\n",
    "            first_col = row.find('th') \n",
    "            if first_col:\n",
    "                link = first_col.find('a')\n",
    "                if link:\n",
    "                    hrefs.append(link['href'])\n",
    "\n",
    "        # Extract table rows\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            cols = row.findAll('td')\n",
    "            if cols:\n",
    "                data.append([col.getText() for col in row.findAll(['th', 'td'])])\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        receiver_hrefs = []\n",
    "        runningback_hrefs = []\n",
    "        tightend_hrefs = []\n",
    "        quarterback_hrefs = []\n",
    "\n",
    "        receiver_counts = []\n",
    "        runningback_counts = []\n",
    "        tightend_counts = []\n",
    "        quarterback_counts = []\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            player = str(df.iloc[i, 0])\n",
    "            position = str(df.iloc[i, 1])\n",
    "            snap_counts = int(df.iloc[i, 2])\n",
    "            if position == 'RB':\n",
    "                runningback_hrefs.append(hrefs[i])\n",
    "                runningback_counts.append(snap_counts)\n",
    "            elif position == 'WR':\n",
    "                receiver_hrefs.append(hrefs[i])\n",
    "                receiver_counts.append(snap_counts)\n",
    "            elif position == 'TE':\n",
    "                tightend_hrefs.append(hrefs[i])\n",
    "                tightend_counts.append(snap_counts)\n",
    "            elif position == 'QB':\n",
    "                quarterback_hrefs.append(hrefs[i])\n",
    "                quarterback_counts.append(snap_counts)\n",
    "            \n",
    "\n",
    "        # Getting the appropriate number of players for each position\n",
    "        receiver_max_indices = sorted(range(len(receiver_counts)), key=lambda i: receiver_counts[i], reverse=True)[:3]\n",
    "        runningback_max_indices = sorted(range(len(runningback_counts)), key=lambda i: runningback_counts[i], reverse=True)[:2]\n",
    "        tightend_max_indices = sorted(range(len(tightend_counts)), key=lambda i: tightend_counts[i], reverse=True)[:1]\n",
    "        quarterback_max_indices = sorted(range(len(quarterback_counts)), key=lambda i: quarterback_counts[i], reverse=True)[:1]\n",
    "\n",
    "        # Getting the hrefs for all players that are going to be used\n",
    "        receiver_hrefs = [receiver_hrefs[i] for i in receiver_max_indices]\n",
    "        receiver_hrefs = [href.replace('.htm', '') for href in receiver_hrefs]\n",
    "\n",
    "        runningback_hrefs = [runningback_hrefs[i] for i in runningback_max_indices]\n",
    "        runningback_hrefs = [href.replace('.htm', '') for href in runningback_hrefs]\n",
    "\n",
    "        tightend_hrefs = [tightend_hrefs[i] for i in tightend_max_indices]\n",
    "        tightend_hrefs = [href.replace('.htm', '') for href in tightend_hrefs]\n",
    "\n",
    "        quarterback_hrefs = [quarterback_hrefs[i] for i in quarterback_max_indices]\n",
    "        quarterback_hrefs = [href.replace('.htm', '') for href in quarterback_hrefs]\n",
    "\n",
    "        for href in quarterback_hrefs:\n",
    "            qb_data = []\n",
    "\n",
    "            # Dealing with passing link for QBs\n",
    "\n",
    "            # Special case for Tayson Hill\n",
    "            if href == '/players/H/HillTa00':\n",
    "                ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "                # Load the URL into a DataFrame\n",
    "                url = f\"https://www.pro-football-reference.com{href}.htm\"\n",
    "                tables = pd.read_html(url)\n",
    "\n",
    "                # Extract the 4th table\n",
    "                fourth_table = tables[2]\n",
    "                qb_base_df = fourth_table\n",
    "\n",
    "            else:\n",
    "                qb_passing_link = f\"https://www.pro-football-reference.com{href}.htm#all_passing\"\n",
    "\n",
    "                # Dealing with passing link for quarterbacks\n",
    "\n",
    "                time.sleep(5)\n",
    "\n",
    "                response = requests.get(qb_passing_link)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "                table = soup.find('table')\n",
    "\n",
    "                qb_base_df = pd.read_html(str(table))[0]\n",
    "\n",
    "            qb_rushing_link = f\"https://www.pro-football-reference.com{href}.htm#all_rushing_and_receiving\"\n",
    "\n",
    "            # qb_base_df.columns = qb_base_df.columns.droplevel()\n",
    "\n",
    "            all_abbreviations = pd.read_csv('teams_abbreviations.csv')\n",
    "            all_reference_abbreviation = all_abbreviations['Reference'].tolist()\n",
    "            all_lower_abbreviation = all_abbreviations['Lower'].tolist()\n",
    "            all_main_upper_abbreviation = all_abbreviations['Upper_Reference'].tolist()\n",
    "            all_backup_upper_abbreviation = all_abbreviations['Backup_Upper_Reference'].tolist()\n",
    "\n",
    "            team_name = team.split('/')[-1]\n",
    "            index = all_reference_abbreviation.index(team_name)\n",
    "\n",
    "            if num == 13:\n",
    "                if year in range(2016, 2020):\n",
    "                    upper_name = all_backup_upper_abbreviation[index]\n",
    "                else:\n",
    "                    upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "            elif num == 15:\n",
    "                if year == 2016:\n",
    "                    upper_name = all_backup_upper_abbreviation[index]\n",
    "                else:\n",
    "                    upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "            else:\n",
    "                upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "            qb_age = 0\n",
    "\n",
    "            for i in range(len(qb_base_df)):\n",
    "                year_value = qb_base_df.loc[i, 'Year']\n",
    "                \n",
    "                if pd.notna(year_value) and year_value != '*':  # Check if the value is not NaN\n",
    "                    qb_base_df.loc[i, 'Year'] = str(year_value)[:4]\n",
    "                    df_year = int(qb_base_df.loc[i, 'Year'])\n",
    "\n",
    "                    if df_year == year:\n",
    "                        df_year_index = i\n",
    "                        teams = str(qb_base_df.loc[i, 'Tm'])\n",
    "                        team_team = teams[1:]\n",
    "                        age = int(qb_base_df.loc[i, 'Age'])\n",
    "                        qb_age = age\n",
    "                        break\n",
    "\n",
    "            # Finds where player played on signified team and moves that row up to the Career row\n",
    "            for i in range(len(qb_base_df)):\n",
    "                if (qb_base_df.loc[i, 'Year']) == 'Career':\n",
    "                    if (len(qb_base_df) - i) != 0:\n",
    "                        for x in range(1, len(qb_base_df) - i):\n",
    "                            if (qb_base_df.loc[x + i, 'Tm']) == upper_name:\n",
    "                                qb_base_df.iloc[i, 1:] = qb_base_df.iloc[i + x, 1:]\n",
    "                                break\n",
    "                    else:\n",
    "                        break\n",
    "                    break\n",
    "\n",
    "            # Makes the base qb data frame the career row\n",
    "            for i in range(len(qb_base_df)):\n",
    "                if (qb_base_df.loc[i, 'Year'] == 'Career'):\n",
    "                    qb_base_df = qb_base_df.loc[[i]]\n",
    "                    break\n",
    "\n",
    "            qb_base_df = qb_base_df.reset_index(drop = True)\n",
    "\n",
    "            qb_base_df.loc[0, 'Age'] = qb_age\n",
    "            qb_base_df.loc[0, 'Year'] = year\n",
    "\n",
    "            if href == '/players/H/HillTa00':\n",
    "                columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'QBrec', 'Lng', 'Y/A', 'AY/A', 'Y/C', 'Yds.1', 'NY/A', 'ANY/A', '4QC', 'GWD', 'Awards', 'Y/G', 'QBR']\n",
    "            else:\n",
    "                columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'QBrec', 'Lng', 'Y/A', 'AY/A', 'Y/C', 'Yds.1', 'NY/A', 'ANY/A', '4QC', 'GWD', 'AV', 'Awards', 'Y/G', 'QBR']\n",
    "            # qb_base_df = qb_base_df.drop(columns_to_drop, axis = 1)\n",
    "            try:\n",
    "                qb_base_df = qb_base_df.drop(columns = columns_to_drop, axis = 1)\n",
    "            except KeyError:\n",
    "                # 'Awards' not in columns, remove 'Awards' from the list and drop again\n",
    "                columns_to_drop.remove('Awards')\n",
    "                qb_base_df = qb_base_df.drop(columns = columns_to_drop, axis = 1)\n",
    "\n",
    "            qb_base_df = qb_base_df.reset_index(drop = True)\n",
    "\n",
    "            qb_base_columns = qb_base_df.columns.tolist()\n",
    "            qb_base_columns[3] = 'Qb_Cmp'\n",
    "            qb_base_columns[4] = 'Qb_Att'\n",
    "            qb_base_columns[5] = 'Qb_Cmp%'\n",
    "            qb_base_columns[6] = 'Qb_Yds'\n",
    "            qb_base_columns[7] = 'Qb_Pass_Td'\n",
    "            qb_base_columns[8] = 'Qb_Td%'\n",
    "            qb_base_columns[9] = 'Qb_Int'\n",
    "            qb_base_columns[10] = 'Qb_Int%'\n",
    "            qb_base_columns[11] = 'Qb_Pass_1D'\n",
    "            qb_base_columns[12] = 'Qb_Pass_Succ%'\n",
    "            qb_base_columns[13] = 'Qb_Rate'\n",
    "            qb_base_columns[14] = 'Qb_Sk'\n",
    "            qb_base_columns[15] = 'Qb_Sk%'\n",
    "            qb_base_df.columns = qb_base_columns\n",
    "\n",
    "            qb_base_df = qb_base_df.reset_index(drop=True)\n",
    "\n",
    "            qb_data.append(qb_base_df)\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "            # Working with the Qb rushing url\n",
    "            response = requests.get(qb_rushing_link)\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            table = soup.find('table', {'id': 'rushing_and_receiving'})\n",
    "\n",
    "            qb_rushing_df = pd.read_html(str(table))[0]\n",
    "\n",
    "            qb_rushing_df.columns = qb_rushing_df.columns.droplevel()\n",
    "\n",
    "            qb_age = 0\n",
    "\n",
    "            for i in range(len(qb_rushing_df)):\n",
    "                year_value = qb_rushing_df.loc[i, 'Year']\n",
    "                \n",
    "                if pd.notna(year_value) and year_value != '*':  # Check if the value is not NaN\n",
    "                    qb_rushing_df.loc[i, 'Year'] = str(year_value)[:4]\n",
    "                    df_year = int(qb_rushing_df.loc[i, 'Year'])\n",
    "\n",
    "                    if df_year == year:\n",
    "                        df_year_index = i\n",
    "                        teams = str(qb_rushing_df.loc[i, 'Tm'])\n",
    "                        team_team = teams[1:]\n",
    "                        age = int(qb_rushing_df.loc[i, 'Age'])\n",
    "                        qb_age = age\n",
    "                        break\n",
    "\n",
    "            # Finds where player played on signified team and moves that row up to the Career row\n",
    "            for i in range(len(qb_rushing_df)):\n",
    "                if (qb_rushing_df.loc[i, 'Year']) == 'Career':\n",
    "                    if (len(qb_rushing_df) - i) != 0:\n",
    "                        for x in range(1, len(qb_rushing_df) - i):\n",
    "                            if (qb_rushing_df.loc[x + i, 'Tm']) == upper_name:\n",
    "                                qb_rushing_df.iloc[i, 1:] = qb_rushing_df.iloc[i + x, 1:]\n",
    "                                break\n",
    "                    else:\n",
    "                        break\n",
    "                    break\n",
    "\n",
    "            # Makes the base qb data frame the career row\n",
    "            for i in range(len(qb_rushing_df)):\n",
    "                if (qb_rushing_df.loc[i, 'Year'] == 'Career'):\n",
    "                    qb_rushing_df = qb_rushing_df.loc[[i]]\n",
    "                    break\n",
    "\n",
    "            qb_rushing_df = qb_rushing_df.reset_index(drop = True)\n",
    "\n",
    "            qb_rushing_df.loc[0, 'Age'] = qb_age\n",
    "            qb_rushing_df.loc[0, 'Year'] = year\n",
    "\n",
    "            qb_rushing_columns = qb_rushing_df.columns.tolist()\n",
    "            qb_rushing_columns[7] = 'Qb_Rush_Att'\n",
    "            qb_rushing_columns[8] = 'Qb_Rush_Yds'\n",
    "            qb_rushing_columns[9] = 'Qb_Rush_Td'\n",
    "            qb_rushing_columns[10] = 'Qb_Rush_1D'\n",
    "            qb_rushing_columns[11] = 'Qb_Rush_Succ%'\n",
    "            qb_rushing_columns[28] = 'Qb_Touches'\n",
    "            qb_rushing_columns[32] = 'Qb_Fmb'\n",
    "            qb_rushing_df.columns = qb_rushing_columns\n",
    "\n",
    "            drop_columns = [0, 1, 2, 3, 4, 5, 6, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31]\n",
    "            qb_rushing_df = qb_rushing_df.drop(qb_rushing_df.columns[drop_columns], axis = 1)\n",
    "\n",
    "            qb_rushing_df = qb_rushing_df.reset_index(drop=True)\n",
    "\n",
    "            qb_data.append(qb_rushing_df)\n",
    "\n",
    "            qb_df = pd.concat(qb_data, axis = 1)\n",
    "\n",
    "            qb_df_columns = qb_df.columns.tolist()\n",
    "\n",
    "            qb_df_columns[0] = 'Qb_Year'\n",
    "            qb_df_columns[1] = 'Qb_Age'\n",
    "            qb_df_columns[2] = 'Qb_G'\n",
    "\n",
    "            qb_df.columns = qb_df_columns\n",
    "\n",
    "            # Applying all qb dfs into the overall df\n",
    "            full_clustered_df = pd.read_csv('clustered_df_careers.csv')\n",
    "            all_abbreviations = pd.read_csv('teams_abbreviations.csv')\n",
    "            all_reference_abbreviation = all_abbreviations['Reference'].tolist()\n",
    "            all_lower_abbreviation = all_abbreviations['Lower'].tolist()\n",
    "            all_upper_abbreviation = all_abbreviations['Upper'].tolist()\n",
    "\n",
    "            for r in range(len(full_clustered_df)):\n",
    "                cluster_team_name = full_clustered_df.loc[r, 'team']\n",
    "                team_name = team.split('/')[-1]\n",
    "                season = full_clustered_df.loc[r, 'season']\n",
    "                index = all_reference_abbreviation.index(team_name)\n",
    "                upper_name = all_upper_abbreviation[index]\n",
    "\n",
    "                all_qb_columns = qb_df.columns.tolist()\n",
    "\n",
    "                if cluster_team_name == upper_name:\n",
    "                    if season == year:\n",
    "                        qb_df = qb_df.rename(index={qb_df.index[0]: r})\n",
    "                        row_index = qb_df.index[0]\n",
    "                        for col in all_qb_columns:\n",
    "                            full_clustered_df.loc[r, col] = qb_df.loc[row_index, col]\n",
    "            \n",
    "            full_clustered_df.to_csv('clustered_df_careers.csv', index  = False)\n",
    "            print(f\"{year} quarterback scraped for {team}.\")\n",
    "\n",
    "        # Remove break statement to do all years of a franchise\n",
    "        # break\n",
    "\n",
    "    # Remove break statement to do all franchises\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRAPES CAREER AVERAGES FOR ALL RUNNING BACKS\n",
    "\n",
    "for num in range(30, 32):\n",
    "    # team = team_hrefs[10]\n",
    "    team = team_hrefs[num]\n",
    "\n",
    "    for j, year in enumerate(years):\n",
    "        url = f'https://www.pro-football-reference.com{team}/{year}-snap-counts.htm'\n",
    "\n",
    "        # Send a request to the website\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check for request errors\n",
    "\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the first table\n",
    "        table = soup.find('table', {'id': 'snap_counts'})\n",
    "\n",
    "        # Extract table headers\n",
    "        headers = [th.getText() for th in table.find('thead').findAll('th')]\n",
    "        rows = table.find('tbody').findAll('tr')\n",
    "\n",
    "        hrefs = []\n",
    "        for row in rows:\n",
    "            first_col = row.find('th') \n",
    "            if first_col:\n",
    "                link = first_col.find('a')\n",
    "                if link:\n",
    "                    hrefs.append(link['href'])\n",
    "\n",
    "        # Extract table rows\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            cols = row.findAll('td')\n",
    "            if cols:\n",
    "                data.append([col.getText() for col in row.findAll(['th', 'td'])])\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        receiver_hrefs = []\n",
    "        runningback_hrefs = []\n",
    "        tightend_hrefs = []\n",
    "        quarterback_hrefs = []\n",
    "\n",
    "        receiver_counts = []\n",
    "        runningback_counts = []\n",
    "        tightend_counts = []\n",
    "        quarterback_counts = []\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            player = str(df.iloc[i, 0])\n",
    "            position = str(df.iloc[i, 1])\n",
    "            snap_counts = int(df.iloc[i, 2])\n",
    "            if position == 'RB':\n",
    "                runningback_hrefs.append(hrefs[i])\n",
    "                runningback_counts.append(snap_counts)\n",
    "            elif position == 'WR':\n",
    "                receiver_hrefs.append(hrefs[i])\n",
    "                receiver_counts.append(snap_counts)\n",
    "            elif position == 'TE':\n",
    "                tightend_hrefs.append(hrefs[i])\n",
    "                tightend_counts.append(snap_counts)\n",
    "            elif position == 'QB':\n",
    "                quarterback_hrefs.append(hrefs[i])\n",
    "                quarterback_counts.append(snap_counts)\n",
    "            \n",
    "\n",
    "        # Getting the appropriate number of players for each position\n",
    "        receiver_max_indices = sorted(range(len(receiver_counts)), key=lambda i: receiver_counts[i], reverse=True)[:3]\n",
    "        runningback_max_indices = sorted(range(len(runningback_counts)), key=lambda i: runningback_counts[i], reverse=True)[:2]\n",
    "        tightend_max_indices = sorted(range(len(tightend_counts)), key=lambda i: tightend_counts[i], reverse=True)[:1]\n",
    "        quarterback_max_indices = sorted(range(len(quarterback_counts)), key=lambda i: quarterback_counts[i], reverse=True)[:1]\n",
    "\n",
    "        # Getting the hrefs for all players that are going to be used\n",
    "        receiver_hrefs = [receiver_hrefs[i] for i in receiver_max_indices]\n",
    "        receiver_hrefs = [href.replace('.htm', '') for href in receiver_hrefs]\n",
    "\n",
    "        runningback_hrefs = [runningback_hrefs[i] for i in runningback_max_indices]\n",
    "        runningback_hrefs = [href.replace('.htm', '') for href in runningback_hrefs]\n",
    "\n",
    "        tightend_hrefs = [tightend_hrefs[i] for i in tightend_max_indices]\n",
    "        tightend_hrefs = [href.replace('.htm', '') for href in tightend_hrefs]\n",
    "\n",
    "        quarterback_hrefs = [quarterback_hrefs[i] for i in quarterback_max_indices]\n",
    "        quarterback_hrefs = [href.replace('.htm', '') for href in quarterback_hrefs]\n",
    "\n",
    "        # Used for distinguishing between first and second string running backs\n",
    "        u = 1\n",
    "\n",
    "        for href in runningback_hrefs:\n",
    "            rb_data = []\n",
    "\n",
    "            rb_base_link = f\"https://www.pro-football-reference.com{href}.htm\"\n",
    "            # rb_fantasy_link = f\"https://www.pro-football-reference.com{href}/fantasy/{year}/\"\n",
    "            rb_fantasy_link = f\"https://www.pro-football-reference.com{href}/fantasy/\"\n",
    "\n",
    "            # Dealing with the base df for runningbacks\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "            response = requests.get(rb_base_link)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            table = soup.find('table')\n",
    "\n",
    "            rb_base_df = pd.read_html(str(table))[0]\n",
    "            rb_base_df.columns = rb_base_df.columns.droplevel()\n",
    "            rb_base_df = rb_base_df.reset_index(drop=True)\n",
    "\n",
    "            all_abbreviations = pd.read_csv('teams_abbreviations.csv')\n",
    "            all_reference_abbreviation = all_abbreviations['Reference'].tolist()\n",
    "            all_lower_abbreviation = all_abbreviations['Lower'].tolist()\n",
    "            all_main_upper_abbreviation = all_abbreviations['Upper_Reference'].tolist()\n",
    "            all_backup_upper_abbreviation = all_abbreviations['Backup_Upper_Reference'].tolist()\n",
    "\n",
    "            team_name = team.split('/')[-1]\n",
    "            index = all_reference_abbreviation.index(team_name)\n",
    "\n",
    "            if num == 13:\n",
    "                if year in range(2016, 2020):\n",
    "                    upper_name = all_backup_upper_abbreviation[index]\n",
    "                else:\n",
    "                    upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "            elif num == 15:\n",
    "                if year == 2016:\n",
    "                    upper_name = all_backup_upper_abbreviation[index]\n",
    "                else:\n",
    "                    upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "            else:\n",
    "                upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "            number_teams = 0\n",
    "\n",
    "            # Finding career averages for a rb for a team\n",
    "            rb_age = 0\n",
    "\n",
    "            for i in range(len(rb_base_df)):\n",
    "                year_value = rb_base_df.loc[i, 'Year']\n",
    "                \n",
    "                if pd.notna(year_value) and year_value != '*':  # Check if the value is not NaN\n",
    "                    rb_base_df.loc[i, 'Year'] = str(year_value)[:4]\n",
    "                    df_year = int(rb_base_df.loc[i, 'Year'])\n",
    "\n",
    "                    if df_year == year:\n",
    "                        df_year_index = i\n",
    "                        teams = str(rb_base_df.loc[i, 'Tm'])\n",
    "                        team_team = teams[1:]\n",
    "                        age = int(rb_base_df.loc[i, 'Age'])\n",
    "                        rb_age = age\n",
    "                        break\n",
    "\n",
    "            # Finds where player played on signified team and moves that row up to the Career row\n",
    "            for i in range(len(rb_base_df)):\n",
    "                if (rb_base_df.loc[i, 'Year']) == 'Career':\n",
    "                    if (len(rb_base_df) - i) != 0:\n",
    "                        for x in range(1, len(rb_base_df) - i):\n",
    "                            if (rb_base_df.loc[x + i, 'Tm']) == upper_name:\n",
    "                                rb_base_df.iloc[i, 1:] = rb_base_df.iloc[i + x, 1:]\n",
    "                                break\n",
    "                    else:\n",
    "                        break\n",
    "                    break\n",
    "\n",
    "            # Makes the base rb data frame the career row\n",
    "            for i in range(len(rb_base_df)):\n",
    "                if (rb_base_df.loc[i, 'Year'] == 'Career'):\n",
    "                    rb_base_df = rb_base_df.loc[[i]]\n",
    "                    break\n",
    "\n",
    "            rb_base_columns = rb_base_df.columns.tolist()\n",
    "\n",
    "            if rb_base_columns[7] == 'Att':\n",
    "                rb_base_columns[7] = f'Rush_Att_{u}'\n",
    "                rb_base_columns[8] = f'Rush_Yds_{u}'\n",
    "                rb_base_columns[9] = f'Rush_Tds_{u}'\n",
    "                rb_base_columns[10] = f'Rush_1D_{u}'\n",
    "                rb_base_columns[11] = f'Rush_Succ%_{u}'\n",
    "                rb_base_columns[16] = f'Rb_Tgt_{u}'\n",
    "                rb_base_columns[17] = f'Rb_Rec_{u}'\n",
    "                rb_base_columns[18] = f'Rb_Rec_Yds_{u}'\n",
    "                rb_base_columns[20] = f'Rb_Rec_Td_{u}'\n",
    "                rb_base_columns[21] = f'Rb_Rec_1D_{u}'\n",
    "                rb_base_columns[22] = f'Rb_Rec_Succ%_{u}'\n",
    "                rb_base_columns[28] = f'Rb_Touch_{u}'\n",
    "                rb_base_columns[32] = f'Rb_Fmb_{u}'\n",
    "\n",
    "                rb_base_df.columns = rb_base_columns\n",
    "\n",
    "                columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'Lng', 'Y/A', 'Y/G', 'Y/R', 'Lng', 'R/G', 'Y/G', 'Ctch%', 'Y/Tgt', 'Y/Tch', 'YScm', 'RRTD', 'AV', 'A/G', 'Awards']\n",
    "                try:\n",
    "                    rb_base_df = rb_base_df.drop(columns = columns_to_drop, axis = 1)\n",
    "                except KeyError:\n",
    "                    # 'Awards' not in columns, remove 'Awards' from the list and drop again\n",
    "                    columns_to_drop.remove('Awards')\n",
    "                    rb_base_df = rb_base_df.drop(columns = columns_to_drop, axis = 1)\n",
    "                    \n",
    "            if rb_base_columns[7] == 'Tgt':\n",
    "                rb_base_columns[28] = f'Rb_Touch_{u}'\n",
    "                rb_base_columns[32] = f'Rb_Fmb_{u}'\n",
    "\n",
    "                rb_base_columns[7] = f'Rb_Tgt_{u}'\n",
    "                rb_base_columns[8] = f'Rb_Rec_{u}'\n",
    "                rb_base_columns[9] = f'Rb_Rec_Yds_{u}'\n",
    "                rb_base_columns[11] = f'Rb_Rec_Td_{u}'\n",
    "                rb_base_columns[12] = f'Rb_Rec_1D_{u}'\n",
    "                rb_base_columns[13] = f'Rb_Rec_Succ%_{u}'\n",
    "\n",
    "                rb_base_columns[19] = f'Rush_Att_{u}'\n",
    "                rb_base_columns[20] = f'Rush_Yds_{u}'\n",
    "                rb_base_columns[21] = f'Rush_Tds_{u}'\n",
    "                rb_base_columns[22] = f'Rush_1D_{u}'\n",
    "                rb_base_columns[23] = f'Rush_Succ%_{u}'\n",
    "\n",
    "                rb_base_df.columns = rb_base_columns\n",
    "\n",
    "                columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'Y/R', 'Lng', 'R/G', 'Y/G', 'Ctch%', 'Y/Tgt', 'Lng', 'Y/A', 'Y/G', 'A/G', 'Y/Tch', 'YScm', 'RRTD', 'AV', 'Awards']\n",
    "                try:\n",
    "                    rb_base_df = rb_base_df.drop(columns = columns_to_drop, axis = 1)\n",
    "                except KeyError:\n",
    "                    # 'Awards' not in columns, remove 'Awards' from the list and drop again\n",
    "                    columns_to_drop.remove('Awards')\n",
    "                    rb_base_df = rb_base_df.drop(columns = columns_to_drop, axis = 1)\n",
    "\n",
    "            rb_base_df = rb_base_df.reset_index(drop=True)\n",
    "\n",
    "            rb_data.append(rb_base_df)\n",
    "\n",
    "            rb_df = pd.concat(rb_data, axis = 1)\n",
    "\n",
    "            rb_df = rb_df.reset_index(drop=True)\n",
    "\n",
    "            rb_df_columns = rb_df.columns.tolist()\n",
    "            rb_df_columns[0] = f'Year_{u}'\n",
    "            rb_df_columns[1] = f'Rb_Age_{u}'\n",
    "            rb_df_columns[2] = f'Rb_G_{u}'\n",
    "            rb_df.columns = rb_df_columns\n",
    "\n",
    "            rb_df.loc[0, f'Year_{u}'] = year\n",
    "            rb_df.loc[0, f'Rb_Age_{u}'] = rb_age\n",
    "\n",
    "            # Applying all rb dfs into the overall df\n",
    "            full_clustered_df = pd.read_csv('clustered_df_careers_rb.csv')\n",
    "            all_abbreviations = pd.read_csv('teams_abbreviations.csv')\n",
    "            all_reference_abbreviation = all_abbreviations['Reference'].tolist()\n",
    "            all_lower_abbreviation = all_abbreviations['Lower'].tolist()\n",
    "            all_upper_abbreviation = all_abbreviations['Upper'].tolist()\n",
    "\n",
    "            for r in range(len(full_clustered_df)):\n",
    "                cluster_team_name = full_clustered_df.loc[r, 'team']\n",
    "                team_name = team.split('/')[-1]\n",
    "                season = full_clustered_df.loc[r, 'season']\n",
    "                index = all_reference_abbreviation.index(team_name)\n",
    "                upper_name = all_upper_abbreviation[index]\n",
    "\n",
    "                all_rb_columns = rb_df.columns.tolist()\n",
    "\n",
    "                if cluster_team_name == upper_name:\n",
    "                    if season == year:\n",
    "                        rb_df = rb_df.rename(index={rb_df.index[0]: r})\n",
    "                        row_index = rb_df.index[0]\n",
    "                        for col in all_rb_columns:\n",
    "                            full_clustered_df.loc[r, col] = rb_df.loc[row_index, col]\n",
    "            \n",
    "            full_clustered_df.to_csv('clustered_df_careers_rb.csv', index  = False)\n",
    "            print(f\"{year}, {u} string runningback scraped for {team}.\")\n",
    "\n",
    "            u += 1\n",
    "\n",
    "        # Remove break statement to do all years of a franchise\n",
    "        # break\n",
    "\n",
    "    # Remove break statement to do all franchises\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRAPES CAREER AVERAGES FOR ALL WIDE RECEIVERS\n",
    "\n",
    "for num in range(30, 32):\n",
    "    # team = team_hrefs[10]\n",
    "    team = team_hrefs[num]\n",
    "\n",
    "    for j, year in enumerate(years):\n",
    "        url = f'https://www.pro-football-reference.com{team}/{year}-snap-counts.htm'\n",
    "\n",
    "        # Send a request to the website\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check for request errors\n",
    "\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the first table\n",
    "        table = soup.find('table', {'id': 'snap_counts'})\n",
    "\n",
    "        # Extract table headers\n",
    "        headers = [th.getText() for th in table.find('thead').findAll('th')]\n",
    "        rows = table.find('tbody').findAll('tr')\n",
    "\n",
    "        hrefs = []\n",
    "        for row in rows:\n",
    "            first_col = row.find('th') \n",
    "            if first_col:\n",
    "                link = first_col.find('a')\n",
    "                if link:\n",
    "                    hrefs.append(link['href'])\n",
    "\n",
    "        # Extract table rows\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            cols = row.findAll('td')\n",
    "            if cols:\n",
    "                data.append([col.getText() for col in row.findAll(['th', 'td'])])\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        receiver_hrefs = []\n",
    "        runningback_hrefs = []\n",
    "        tightend_hrefs = []\n",
    "        quarterback_hrefs = []\n",
    "\n",
    "        receiver_counts = []\n",
    "        runningback_counts = []\n",
    "        tightend_counts = []\n",
    "        quarterback_counts = []\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            player = str(df.iloc[i, 0])\n",
    "            position = str(df.iloc[i, 1])\n",
    "            snap_counts = int(df.iloc[i, 2])\n",
    "            if position == 'RB':\n",
    "                runningback_hrefs.append(hrefs[i])\n",
    "                runningback_counts.append(snap_counts)\n",
    "            elif position == 'WR':\n",
    "                receiver_hrefs.append(hrefs[i])\n",
    "                receiver_counts.append(snap_counts)\n",
    "            elif position == 'TE':\n",
    "                tightend_hrefs.append(hrefs[i])\n",
    "                tightend_counts.append(snap_counts)\n",
    "            elif position == 'QB':\n",
    "                quarterback_hrefs.append(hrefs[i])\n",
    "                quarterback_counts.append(snap_counts)\n",
    "            \n",
    "\n",
    "        # Getting the appropriate number of players for each position\n",
    "        receiver_max_indices = sorted(range(len(receiver_counts)), key=lambda i: receiver_counts[i], reverse=True)[:3]\n",
    "        runningback_max_indices = sorted(range(len(runningback_counts)), key=lambda i: runningback_counts[i], reverse=True)[:2]\n",
    "        tightend_max_indices = sorted(range(len(tightend_counts)), key=lambda i: tightend_counts[i], reverse=True)[:1]\n",
    "        quarterback_max_indices = sorted(range(len(quarterback_counts)), key=lambda i: quarterback_counts[i], reverse=True)[:1]\n",
    "\n",
    "        # Getting the hrefs for all players that are going to be used\n",
    "        receiver_hrefs = [receiver_hrefs[i] for i in receiver_max_indices]\n",
    "        receiver_hrefs = [href.replace('.htm', '') for href in receiver_hrefs]\n",
    "\n",
    "        runningback_hrefs = [runningback_hrefs[i] for i in runningback_max_indices]\n",
    "        runningback_hrefs = [href.replace('.htm', '') for href in runningback_hrefs]\n",
    "\n",
    "        tightend_hrefs = [tightend_hrefs[i] for i in tightend_max_indices]\n",
    "        tightend_hrefs = [href.replace('.htm', '') for href in tightend_hrefs]\n",
    "\n",
    "        quarterback_hrefs = [quarterback_hrefs[i] for i in quarterback_max_indices]\n",
    "        quarterback_hrefs = [href.replace('.htm', '') for href in quarterback_hrefs]\n",
    "\n",
    "        # Used for distinguishing between first, second, and third string wide receivers\n",
    "        u = 1\n",
    "\n",
    "        for href in receiver_hrefs:\n",
    "            wr_data = []\n",
    "\n",
    "            if href == '/players/P/PattCo00':\n",
    "                wr_base_link = f'https://www.pro-football-reference.com{href}.htm#all_rushing_and_receiving'\n",
    "            else:\n",
    "                wr_base_link = f'https://www.pro-football-reference.com{href}.htm#all_receiving_and_rushing'\n",
    "                \n",
    "\n",
    "            # Dealing with the base df for wide receivers\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "            response = requests.get(wr_base_link)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            table = soup.find('table')\n",
    "\n",
    "            wr_base_df = pd.read_html(str(table))[0]\n",
    "\n",
    "            # wr_base_df.columns = wr_base_df.columns.droplevel()\n",
    "\n",
    "            def drop_column_level_if_possible(df):\n",
    "                if isinstance(df.columns, pd.MultiIndex):\n",
    "                    df.columns = df.columns.droplevel()\n",
    "                return df\n",
    "\n",
    "            kick_return_hrefs = ['/players/M/McClRa00', '/players/A/AgneJa00']\n",
    "\n",
    "            if href == '/players/P/PryoTe00':\n",
    "                ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "                tables = pd.read_html(wr_base_link)\n",
    "\n",
    "                # Extract the 4th table\n",
    "                wr_base_df = tables[2]\n",
    "\n",
    "            if href in kick_return_hrefs:\n",
    "                ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "                tables = pd.read_html(wr_base_link)\n",
    "\n",
    "                # Extract the 4th table\n",
    "                wr_base_df = tables[2]\n",
    "\n",
    "            # Drops level if df has more than one level\n",
    "            wr_base_df = drop_column_level_if_possible(wr_base_df)\n",
    "\n",
    "            all_abbreviations = pd.read_csv('teams_abbreviations.csv')\n",
    "            all_reference_abbreviation = all_abbreviations['Reference'].tolist()\n",
    "            all_lower_abbreviation = all_abbreviations['Lower'].tolist()\n",
    "            all_main_upper_abbreviation = all_abbreviations['Upper_Reference'].tolist()\n",
    "            all_backup_upper_abbreviation = all_abbreviations['Backup_Upper_Reference'].tolist()\n",
    "\n",
    "            team_name = team.split('/')[-1]\n",
    "            index = all_reference_abbreviation.index(team_name)\n",
    "\n",
    "            if num == 13:\n",
    "                if year in range(2016, 2020):\n",
    "                    upper_name = all_backup_upper_abbreviation[index]\n",
    "                else:\n",
    "                    upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "            elif num == 15:\n",
    "                if year == 2016:\n",
    "                    upper_name = all_backup_upper_abbreviation[index]\n",
    "                else:\n",
    "                    upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "            else:\n",
    "                upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "            number_teams = 0\n",
    "\n",
    "            wr_age = 0\n",
    "\n",
    "            for i in range(len(wr_base_df)):\n",
    "                year_value = wr_base_df.loc[i, 'Year']\n",
    "                \n",
    "                if pd.notna(year_value) and year_value != '*':  # Check if the value is not NaN\n",
    "                    wr_base_df.loc[i, 'Year'] = str(year_value)[:4]\n",
    "                    df_year = int(wr_base_df.loc[i, 'Year'])\n",
    "\n",
    "                    if df_year == year:\n",
    "                        df_year_index = i\n",
    "                        teams = str(wr_base_df.loc[i, 'Tm'])\n",
    "                        team_team = teams[1:]\n",
    "                        age = int(wr_base_df.loc[i, 'Age'])\n",
    "                        wr_age = age\n",
    "                        break\n",
    "\n",
    "            # Finds where player played on signified team and moves that row up to the Career row\n",
    "            for i in range(len(wr_base_df)):\n",
    "                if (wr_base_df.loc[i, 'Year']) == 'Career':\n",
    "                    if (len(wr_base_df) - i) != 0:\n",
    "                        for x in range(1, len(wr_base_df) - i):\n",
    "                            if (wr_base_df.loc[x + i, 'Tm']) == upper_name:\n",
    "                                wr_base_df.iloc[i, 1:] = wr_base_df.iloc[i + x, 1:]\n",
    "                                break\n",
    "                    else:\n",
    "                        break\n",
    "                    break\n",
    "\n",
    "            # Makes the base rb data frame the career row\n",
    "            for i in range(len(wr_base_df)):\n",
    "                if (wr_base_df.loc[i, 'Year'] == 'Career'):\n",
    "                    wr_base_df = wr_base_df.loc[[i]]\n",
    "                    break\n",
    "\n",
    "            wr_base_columns = wr_base_df.columns.tolist()\n",
    "\n",
    "            if wr_base_columns[7] == 'Att':\n",
    "                wr_base_columns[7] = f'Rec_Rush_Att_{u}'\n",
    "                wr_base_columns[8] = f'Rec_Rush_Yds_{u}'\n",
    "                wr_base_columns[9] = f'Rec_Rush_Tds_{u}'\n",
    "                wr_base_columns[10] = f'Rec_Rush_1D_{u}'\n",
    "                wr_base_columns[11] = f'Rec_Rush_Succ%_{u}'\n",
    "                wr_base_columns[16] = f'Rec_Tgt_{u}'\n",
    "                wr_base_columns[17] = f'Wr_Rec_{u}'\n",
    "                wr_base_columns[18] = f'Rec_Yds_{u}'\n",
    "                wr_base_columns[20] = f'Rec_Tds_{u}'\n",
    "                wr_base_columns[21] = f'Rec_1D_{u}'\n",
    "                wr_base_columns[22] = f'Rec_Succ%_{u}'\n",
    "                wr_base_columns[28] = f'Rec_Touch_{u}'\n",
    "                wr_base_columns[32] = f'Rec_Fumb_{u}'\n",
    "\n",
    "                wr_base_df.columns = wr_base_columns\n",
    "\n",
    "                if href == '/players/P/PryoTe00':\n",
    "                    columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'Y/R', 'Lng', 'R/G', 'Y/G', 'Ctch%', 'Y/Tgt', 'Lng', 'Y/A', 'Y/G', 'A/G', 'Y/Tch', 'YScm', 'RRTD', 'Awards']\n",
    "                elif href == '/players/M/McClRa00':\n",
    "                    columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'Y/R', 'Lng', 'R/G', 'Y/G', 'Ctch%', 'Y/Tgt', 'Lng', 'Y/A', 'Y/G', 'A/G', 'Y/Tch', 'YScm', 'RRTD', 'Awards']\n",
    "                elif href == '/players/A/AgneJa00':\n",
    "                    columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'Y/R', 'Lng', 'R/G', 'Y/G', 'Ctch%', 'Y/Tgt', 'Lng', 'Y/A', 'Y/G', 'A/G', 'Y/Tch', 'YScm', 'RRTD', 'Awards']\n",
    "                else:\n",
    "                    columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'Lng', 'Y/A', 'Y/G', 'Y/R', 'Lng', 'R/G', 'Y/G', 'Ctch%', 'Y/Tgt', 'Y/Tch', 'YScm', 'RRTD', 'AV', 'A/G', 'Awards']              \n",
    "                try:\n",
    "                    wr_base_df = wr_base_df.drop(columns = columns_to_drop, axis = 1)\n",
    "                except KeyError:\n",
    "                    # 'Awards' not in columns, remove 'Awards' from the list and drop again\n",
    "                    columns_to_drop.remove('Awards')\n",
    "                    wr_base_df = wr_base_df.drop(columns = columns_to_drop, axis = 1)\n",
    "\n",
    "            else:\n",
    "                wr_base_columns[7] = f'Rec_Tgt_{u}'\n",
    "                wr_base_columns[8] = f'Wr_Rec_{u}'\n",
    "                wr_base_columns[9] = f'Rec_Yds_{u}'\n",
    "                wr_base_columns[11] = f'Rec_Tds_{u}'\n",
    "                wr_base_columns[12] = f'Rec_1D_{u}'\n",
    "                wr_base_columns[13] = f'Rec_Succ%_{u}'\n",
    "                wr_base_columns[19] = f'Rec_Rush_Att_{u}'\n",
    "                wr_base_columns[20] = f'Rec_Rush_Yds_{u}'\n",
    "                wr_base_columns[21] = f'Rec_Rush_Tds_{u}'\n",
    "                wr_base_columns[22] = f'Rec_Rush_1D_{u}'\n",
    "                wr_base_columns[23] = f'Rec_Rush_Succ%_{u}'\n",
    "                wr_base_columns[28] = f'Rec_Touch_{u}'\n",
    "                wr_base_columns[32] = f'Rec_Fumb_{u}'\n",
    "\n",
    "                wr_base_df.columns = wr_base_columns\n",
    "\n",
    "                wr_base_df = wr_base_df.reset_index(drop=True)\n",
    "\n",
    "                if href == '/players/P/PryoTe00':\n",
    "                    columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'Y/R', 'Lng', 'R/G', 'Y/G', 'Ctch%', 'Y/Tgt', 'Lng', 'Y/A', 'Y/G', 'A/G', 'Y/Tch', 'YScm', 'RRTD', 'Awards']\n",
    "                elif href == '/players/M/McClRa00':\n",
    "                    columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'Y/R', 'Lng', 'R/G', 'Y/G', 'Ctch%', 'Y/Tgt', 'Lng', 'Y/A', 'Y/G', 'A/G', 'Y/Tch', 'YScm', 'RRTD', 'Awards']\n",
    "                elif href == '/players/A/AgneJa00':\n",
    "                    columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'Y/R', 'Lng', 'R/G', 'Y/G', 'Ctch%', 'Y/Tgt', 'Lng', 'Y/A', 'Y/G', 'A/G', 'Y/Tch', 'YScm', 'RRTD', 'Awards']\n",
    "                else:\n",
    "                    columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'Y/R', 'Lng', 'R/G', 'Y/G', 'Ctch%', 'Y/Tgt', 'Lng', 'Y/A', 'Y/G', 'A/G', 'Y/Tch', 'YScm', 'RRTD', 'AV', 'Awards']\n",
    "                try:\n",
    "                    wr_base_df = wr_base_df.drop(columns = columns_to_drop, axis = 1)\n",
    "                except KeyError:\n",
    "                    # 'Awards' not in columns, remove 'Awards' from the list and drop again\n",
    "                    columns_to_drop.remove('Awards')\n",
    "                    wr_base_df = wr_base_df.drop(columns = columns_to_drop, axis = 1)\n",
    "\n",
    "            wr_data.append(wr_base_df)\n",
    "\n",
    "            wr_df = pd.concat(wr_data, axis = 1)\n",
    "\n",
    "            wr_df = wr_df.reset_index(drop=True)\n",
    "\n",
    "            wr_df_columns = wr_df.columns.tolist()\n",
    "            wr_df_columns[0] = f'Year_{u}'\n",
    "            wr_df_columns[1] = f'Wr_Age_{u}'\n",
    "            wr_df_columns[2] = f'Wr_G_{u}'\n",
    "            wr_df.columns = wr_df_columns\n",
    "\n",
    "            wr_df = wr_df.fillna(0)\n",
    "\n",
    "            wr_df.loc[0, f'Year_{u}'] = year\n",
    "            wr_df.loc[0, f'Wr_Age_{u}'] = wr_age\n",
    "\n",
    "            # Applying all wr dfs into the overall df\n",
    "            full_clustered_df = pd.read_csv('clustered_df_careers_wr.csv')\n",
    "            all_abbreviations = pd.read_csv('teams_abbreviations.csv')\n",
    "            all_reference_abbreviation = all_abbreviations['Reference'].tolist()\n",
    "            all_lower_abbreviation = all_abbreviations['Lower'].tolist()\n",
    "            all_upper_abbreviation = all_abbreviations['Upper'].tolist()\n",
    "\n",
    "            for r in range(len(full_clustered_df)):\n",
    "                cluster_team_name = full_clustered_df.loc[r, 'team']\n",
    "                team_name = team.split('/')[-1]\n",
    "                season = full_clustered_df.loc[r, 'season']\n",
    "                index = all_reference_abbreviation.index(team_name)\n",
    "                upper_name = all_upper_abbreviation[index]\n",
    "\n",
    "                all_wr_columns = wr_df.columns.tolist()\n",
    "\n",
    "                if cluster_team_name == upper_name:\n",
    "                    if season == year:\n",
    "                        wr_df = wr_df.rename(index={wr_df.index[0]: r})\n",
    "                        row_index = wr_df.index[0]\n",
    "                        for col in all_wr_columns:\n",
    "                            full_clustered_df.loc[r, col] = wr_df.loc[row_index, col]\n",
    "            \n",
    "            full_clustered_df.to_csv('clustered_df_careers_wr.csv', index  = False)\n",
    "\n",
    "            print(f\"{year}, {u} string wide receiver scraped for {team}.\")\n",
    "\n",
    "            u += 1\n",
    "\n",
    "            # Remove break statement to do all receivers of one year of a franchise\n",
    "            # break\n",
    "\n",
    "        # Remove break statement to do all years of a franchise\n",
    "        # break\n",
    "\n",
    "    # Remove break statement to do all franchises\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRAPES CAREER AVERAGES FOR ALL TIGHT ENDS\n",
    "\n",
    "for num in range(31, 32):\n",
    "    # team = team_hrefs[10]\n",
    "    team = team_hrefs[num]\n",
    "\n",
    "    for j, year in enumerate(years):\n",
    "        url = f'https://www.pro-football-reference.com{team}/{year}-snap-counts.htm'\n",
    "\n",
    "        # Send a request to the website\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check for request errors\n",
    "\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find the first table\n",
    "        table = soup.find('table', {'id': 'snap_counts'})\n",
    "\n",
    "        # Extract table headers\n",
    "        headers = [th.getText() for th in table.find('thead').findAll('th')]\n",
    "        rows = table.find('tbody').findAll('tr')\n",
    "\n",
    "        hrefs = []\n",
    "        for row in rows:\n",
    "            first_col = row.find('th') \n",
    "            if first_col:\n",
    "                link = first_col.find('a')\n",
    "                if link:\n",
    "                    hrefs.append(link['href'])\n",
    "\n",
    "        # Extract table rows\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            cols = row.findAll('td')\n",
    "            if cols:\n",
    "                data.append([col.getText() for col in row.findAll(['th', 'td'])])\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        receiver_hrefs = []\n",
    "        runningback_hrefs = []\n",
    "        tightend_hrefs = []\n",
    "        quarterback_hrefs = []\n",
    "\n",
    "        receiver_counts = []\n",
    "        runningback_counts = []\n",
    "        tightend_counts = []\n",
    "        quarterback_counts = []\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            player = str(df.iloc[i, 0])\n",
    "            position = str(df.iloc[i, 1])\n",
    "            snap_counts = int(df.iloc[i, 2])\n",
    "            if position == 'RB':\n",
    "                runningback_hrefs.append(hrefs[i])\n",
    "                runningback_counts.append(snap_counts)\n",
    "            elif position == 'WR':\n",
    "                receiver_hrefs.append(hrefs[i])\n",
    "                receiver_counts.append(snap_counts)\n",
    "            elif position == 'TE':\n",
    "                tightend_hrefs.append(hrefs[i])\n",
    "                tightend_counts.append(snap_counts)\n",
    "            elif position == 'QB':\n",
    "                quarterback_hrefs.append(hrefs[i])\n",
    "                quarterback_counts.append(snap_counts)\n",
    "            \n",
    "\n",
    "        # Getting the appropriate number of players for each position\n",
    "        receiver_max_indices = sorted(range(len(receiver_counts)), key=lambda i: receiver_counts[i], reverse=True)[:3]\n",
    "        runningback_max_indices = sorted(range(len(runningback_counts)), key=lambda i: runningback_counts[i], reverse=True)[:2]\n",
    "        tightend_max_indices = sorted(range(len(tightend_counts)), key=lambda i: tightend_counts[i], reverse=True)[:1]\n",
    "        quarterback_max_indices = sorted(range(len(quarterback_counts)), key=lambda i: quarterback_counts[i], reverse=True)[:1]\n",
    "\n",
    "        # Getting the hrefs for all players that are going to be used\n",
    "        receiver_hrefs = [receiver_hrefs[i] for i in receiver_max_indices]\n",
    "        receiver_hrefs = [href.replace('.htm', '') for href in receiver_hrefs]\n",
    "\n",
    "        runningback_hrefs = [runningback_hrefs[i] for i in runningback_max_indices]\n",
    "        runningback_hrefs = [href.replace('.htm', '') for href in runningback_hrefs]\n",
    "\n",
    "        tightend_hrefs = [tightend_hrefs[i] for i in tightend_max_indices]\n",
    "        tightend_hrefs = [href.replace('.htm', '') for href in tightend_hrefs]\n",
    "\n",
    "        quarterback_hrefs = [quarterback_hrefs[i] for i in quarterback_max_indices]\n",
    "        quarterback_hrefs = [href.replace('.htm', '') for href in quarterback_hrefs]\n",
    "\n",
    "        for href in tightend_hrefs:\n",
    "            te_data = []\n",
    "\n",
    "            te_base_link = f\"https://www.pro-football-reference.com{href}.htm#all_receiving_and_rushing\"\n",
    "                \n",
    "            # Dealing with the base df for tight ends\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "            response = requests.get(te_base_link)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            table = soup.find('table')\n",
    "\n",
    "            te_base_df = pd.read_html(str(table))[0]\n",
    "\n",
    "            te_base_df.columns = te_base_df.columns.droplevel()\n",
    "\n",
    "            all_abbreviations = pd.read_csv('teams_abbreviations.csv')\n",
    "            all_reference_abbreviation = all_abbreviations['Reference'].tolist()\n",
    "            all_lower_abbreviation = all_abbreviations['Lower'].tolist()\n",
    "            all_main_upper_abbreviation = all_abbreviations['Upper_Reference'].tolist()\n",
    "            all_backup_upper_abbreviation = all_abbreviations['Backup_Upper_Reference'].tolist()\n",
    "\n",
    "            team_name = team.split('/')[-1]\n",
    "            index = all_reference_abbreviation.index(team_name)\n",
    "\n",
    "            if num == 13:\n",
    "                if year in range(2016, 2020):\n",
    "                    upper_name = all_backup_upper_abbreviation[index]\n",
    "                else:\n",
    "                    upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "            elif num == 15:\n",
    "                if year == 2016:\n",
    "                    upper_name = all_backup_upper_abbreviation[index]\n",
    "                else:\n",
    "                    upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "            else:\n",
    "                upper_name = all_main_upper_abbreviation[index]\n",
    "\n",
    "            number_teams = 0\n",
    "\n",
    "            te_age = 0\n",
    "\n",
    "            for i in range(len(te_base_df)):\n",
    "                year_value = te_base_df.loc[i, 'Year']\n",
    "                \n",
    "                if pd.notna(year_value) and year_value != '*':  # Check if the value is not NaN\n",
    "                    te_base_df.loc[i, 'Year'] = str(year_value)[:4]\n",
    "                    df_year = int(te_base_df.loc[i, 'Year'])\n",
    "\n",
    "                    if df_year == year:\n",
    "                        df_year_index = i\n",
    "                        teams = str(te_base_df.loc[i, 'Tm'])\n",
    "                        team_team = teams[1:]\n",
    "                        age = int(te_base_df.loc[i, 'Age'])\n",
    "                        te_age = age\n",
    "                        break\n",
    "\n",
    "            # Finds where player played on signified team and moves that row up to the Career row\n",
    "            for i in range(len(te_base_df)):\n",
    "                if (te_base_df.loc[i, 'Year']) == 'Career':\n",
    "                    if (len(te_base_df) - i) != 0:\n",
    "                        for x in range(1, len(te_base_df) - i):\n",
    "                            if (te_base_df.loc[x + i, 'Tm']) == upper_name:\n",
    "                                te_base_df.iloc[i, 1:] = te_base_df.iloc[i + x, 1:]\n",
    "                                break\n",
    "                    else:\n",
    "                        break\n",
    "                    break\n",
    "\n",
    "            # Makes the base rb data frame the career row\n",
    "            for i in range(len(te_base_df)):\n",
    "                if (te_base_df.loc[i, 'Year'] == 'Career'):\n",
    "                    te_base_df = te_base_df.loc[[i]]\n",
    "                    break\n",
    "\n",
    "            te_base_columns = te_base_df.columns.tolist()\n",
    "\n",
    "            te_base_columns[7] = 'Te_Rec_Tgt'\n",
    "            te_base_columns[8] = 'Te_Rec'\n",
    "            te_base_columns[9] = 'Te_Rec_Yds'\n",
    "            te_base_columns[11] = 'Te_Rec_Tds'\n",
    "            te_base_columns[12] = 'Te_Rec_1D'\n",
    "            te_base_columns[13] = 'Te_Rec_Succ%'\n",
    "            te_base_columns[19] = 'Te_Rec_Rush_Att'\n",
    "            te_base_columns[20] = 'Te_Rec_Rush_Yds'\n",
    "            te_base_columns[21] = 'Te_Rec_Rush_Tds'\n",
    "            te_base_columns[22] = 'Te_Rec_Rush_1D'\n",
    "            te_base_columns[23] = 'Te_Rec_Rush_Succ%'\n",
    "            te_base_columns[28] = 'Te_Rec_Touch'\n",
    "            te_base_columns[32] = 'Te_Rec_Fumb'\n",
    "\n",
    "            te_base_df.columns = te_base_columns\n",
    "\n",
    "            te_base_df = te_base_df.reset_index(drop=True)\n",
    "\n",
    "            columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'Y/R', 'Lng', 'R/G', 'Y/G', 'Ctch%', 'Y/Tgt', 'Lng', 'Y/A', 'Y/G', 'A/G', 'Y/Tch', 'YScm', 'RRTD', 'AV', 'Awards']\n",
    "            try:\n",
    "                te_base_df = te_base_df.drop(columns = columns_to_drop, axis = 1)\n",
    "            except KeyError:\n",
    "                # 'Awards' not in columns, remove 'Awards' from the list and drop again\n",
    "                columns_to_drop.remove('Awards')\n",
    "                te_base_df = te_base_df.drop(columns = columns_to_drop, axis = 1)\n",
    "\n",
    "            te_data.append(te_base_df)\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "            te_df = pd.concat(te_data, axis = 1)\n",
    "\n",
    "            te_df = te_df.reset_index(drop=True)\n",
    "\n",
    "            te_df_columns = te_df.columns.tolist()\n",
    "            te_df_columns[0] = 'Te_Year'\n",
    "            te_df_columns[1] = 'Te_Age'\n",
    "            te_df_columns[2] = 'Te_G'\n",
    "            te_df.columns = te_df_columns\n",
    "\n",
    "            te_df = te_df.fillna(0)\n",
    "\n",
    "            te_df.loc[0, 'Te_Year'] = year\n",
    "            te_df.loc[0, 'Te_Age'] = te_age\n",
    "\n",
    "            # Applying all wr dfs into the overall df\n",
    "            full_clustered_df = pd.read_csv('clustered_df_careers_te.csv')\n",
    "            all_abbreviations = pd.read_csv('teams_abbreviations.csv')\n",
    "            all_reference_abbreviation = all_abbreviations['Reference'].tolist()\n",
    "            all_lower_abbreviation = all_abbreviations['Lower'].tolist()\n",
    "            all_upper_abbreviation = all_abbreviations['Upper'].tolist()\n",
    "\n",
    "            for r in range(len(full_clustered_df)):\n",
    "                cluster_team_name = full_clustered_df.loc[r, 'team']\n",
    "                team_name = team.split('/')[-1]\n",
    "                season = full_clustered_df.loc[r, 'season']\n",
    "                index = all_reference_abbreviation.index(team_name)\n",
    "                upper_name = all_upper_abbreviation[index]\n",
    "\n",
    "                all_te_columns = te_df.columns.tolist()\n",
    "\n",
    "                if cluster_team_name == upper_name:\n",
    "                    if season == year:\n",
    "                        te_df = te_df.rename(index={te_df.index[0]: r})\n",
    "                        row_index = te_df.index[0]\n",
    "                        for col in all_te_columns:\n",
    "                            full_clustered_df.loc[r, col] = te_df.loc[row_index, col]\n",
    "            \n",
    "            full_clustered_df.to_csv('clustered_df_careers_te.csv', index  = False)\n",
    "            print(f\"{year} tight end scraped for {team}.\")\n",
    "\n",
    "            # Remove break statement to do all receivers of one year of a franchise\n",
    "            # break\n",
    "\n",
    "        # Remove break statement to do all years of a franchise\n",
    "        # break\n",
    "\n",
    "    # Remove break statement to do all franchises\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all career statistics to per-game\n",
    "\n",
    "dirty_df = pd.read_csv('clustered_df_careers_all_positions.csv')\n",
    "\n",
    "# stats.csv is a .csv containing all statistics that need to be converted to per-game statistics (leaving alone statistics like percentages and ratings)\n",
    "stat_df = pd.read_csv('stats.csv')\n",
    "\n",
    "qb_stats = stat_df['Qb_Stats'].tolist()\n",
    "rb_stats_1 = stat_df['Rb_1_Stats'].tolist()\n",
    "rb_stats_2 = stat_df['Rb_2_Stats'].tolist()\n",
    "wr_stats_1 = stat_df['Wr_1_Stats'].tolist()\n",
    "wr_stats_2 = stat_df['Wr_2_Stats'].tolist()\n",
    "wr_stats_3 = stat_df['Wr_3_Stats'].tolist()\n",
    "te_stats = stat_df['Te_Stats'].tolist()\n",
    "\n",
    "for col in dirty_df.columns:\n",
    "    if col in qb_stats:\n",
    "        dirty_df.loc[:, col] = dirty_df.loc[:, col].astype(float) / dirty_df.loc[:, 'Qb_G'].astype(float)\n",
    "    elif col in rb_stats_1:\n",
    "        dirty_df.loc[:, col] = dirty_df.loc[:, col].astype(float) / dirty_df.loc[:, 'Rb_G_1'].astype(float)\n",
    "    elif col in rb_stats_2:\n",
    "        dirty_df.loc[:, col] = dirty_df.loc[:, col].astype(float) / dirty_df.loc[:, 'Rb_G_2'].astype(float)\n",
    "    elif col in wr_stats_1:\n",
    "        dirty_df.loc[:, col] = dirty_df.loc[:, col].astype(float) / dirty_df.loc[:, 'Wr_G_1'].astype(float)\n",
    "    elif col in wr_stats_2:\n",
    "        dirty_df.loc[:, col] = dirty_df.loc[:, col].astype(float) / dirty_df.loc[:, 'Wr_G_2'].astype(float)\n",
    "    elif col in wr_stats_3:\n",
    "        dirty_df.loc[:, col] = dirty_df.loc[:, col].astype(float) / dirty_df.loc[:, 'Wr_G_3'].astype(float)\n",
    "    elif col in te_stats:\n",
    "        dirty_df.loc[:, col] = dirty_df.loc[:, col].astype(float) / dirty_df.loc[:, 'Te_G'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling empty spaces with 0\n",
    "\n",
    "dirty_df = dirty_df.fillna(0)\n",
    "\n",
    "dirty_df.to_csv('career_per_game.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting NFL tendency data based on past career average data.\n",
    "\n",
    "df = pd.read_csv('Read in career average df for past seasons')\n",
    "\n",
    "columns = df.columns\n",
    "\n",
    "# Step 2: Separate features and targets\n",
    "target = columns[6:42]\n",
    "features = columns[42:]\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Initialize the RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Step 5: Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Step 7: Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Output the MSE value\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting in tendency predictions into another csv\n",
    "\n",
    "new_df = pd.read_csv('clustered_df_careers_all_positions_2024.csv')\n",
    "\n",
    "# Step 2: Ensure that the features are in the same format/order as the training data\n",
    "X_new = new_df[features]  # Use the same 'features' from the previous step\n",
    "\n",
    "# Step 3: Use the trained model to predict the missing target values\n",
    "predictions = rf_model.predict(X_new)  # Use the trained RandomForestRegressor model\n",
    "\n",
    "# Step 4: Fill in the target columns with the predicted values\n",
    "new_df[target] = predictions\n",
    "\n",
    "# Step 5: Save the updated DataFrame to a new CSV file or further process it\n",
    "new_df.to_csv('new_data_with_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model on qb data frame with fantasy results\n",
    "\n",
    "qb_df = pd.read_csv('clustered_df_qb copy.csv')\n",
    "\n",
    "features = columns[6:43]\n",
    "target = 'Qb_FantPt'\n",
    "\n",
    "X = qb_df[features]\n",
    "y = qb_df[target]\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Initialize the RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Step 5: Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Step 7: Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Output the MSE value\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "new_df = pd.read_csv('qb_fantasy_predictions.csv')\n",
    "\n",
    "# Step 2: Ensure that the features are in the same format/order as the training data\n",
    "X_new = new_df[features]  # Use the same 'features' from the previous step\n",
    "\n",
    "# Step 3: Use the trained model to predict the missing target values\n",
    "predictions = rf_model.predict(X_new)  # Use the trained RandomForestRegressor model\n",
    "\n",
    "# Step 4: Fill in the target columns with the predicted values\n",
    "new_df[target] = predictions\n",
    "\n",
    "new_df = new_df.sort_values(by='Qb_FantPt', ascending=False)\n",
    "\n",
    "# Step 5: Save the updated DataFrame to a new CSV file or further process it\n",
    "new_df.to_csv('qb_fantasy_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
