{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import ssl\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining years\n",
    "years = list(range(2016, 2024))\n",
    "\n",
    "# Load initial team data\n",
    "teams_df = pd.read_csv('clustered_df.csv')\n",
    "teams_upper = teams_df[\"team\"].unique().tolist()\n",
    "teams_lower = [team.lower() for team in teams_upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting hrefs\n",
    "\n",
    "def fetch_team_hrefs(url=\"https://www.pro-football-reference.com/years/2023/#all_team_stats\"):\n",
    "    \"\"\"Fetch team hrefs from the website.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    hrefs = [a['href'].replace('.htm', '').rsplit('/', 1)[0] for a in soup.find_all('a', href=True) \n",
    "             if '/teams/' in a['href']]\n",
    "    return list(dict.fromkeys(hrefs[1:]))  # Remove duplicates and first irrelevant href\n",
    "\n",
    "team_hrefs = fetch_team_hrefs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helping with team abbreviations\n",
    "\n",
    "def create_team_abbreviations():\n",
    "    teams_abbreviation = pd.read_csv('teams_abbreviations.csv')\n",
    "    teams_abbreviation['Lower'] = teams_lower\n",
    "    teams_abbreviation['Upper'] = teams_upper\n",
    "    reference_abbreviations = [href.split('/')[-1] for href in team_hrefs]\n",
    "    \n",
    "    for r in range(len(teams_abbreviation)):\n",
    "        if teams_abbreviation.loc[r, 'Lower'] in reference_abbreviations:\n",
    "            teams_abbreviation.loc[r, 'Reference'] = reference_abbreviations[\n",
    "                reference_abbreviations.index(teams_abbreviation.loc[r, 'Lower'])]\n",
    "    \n",
    "    # Manual overrides for specific teams\n",
    "    overrides = {0: 'crd', 2: 'rav', 11: 'gnb', 12: 'htx', 13: 'clt', 15: 'kan', 16: 'ram',\n",
    "                 17: 'sdg', 18: 'rai', 21: 'nwe', 22: 'nor', 28: 'sfo', 29: 'tam', 30: 'oti'}\n",
    "    for idx, ref in overrides.items():\n",
    "        teams_abbreviation.loc[idx, 'Reference'] = ref\n",
    "    \n",
    "    teams_abbreviation.to_csv('team_abbreviations_updated.csv', index=False)\n",
    "\n",
    "create_team_abbreviations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional utility functions\n",
    "\n",
    "def get_team_upper_name(team, year, abbreviations_df):\n",
    "    \"\"\"Determine the correct upper team name based on team and year.\"\"\"\n",
    "    team_name = team.split('/')[-1]\n",
    "    idx = abbreviations_df['Reference'].tolist().index(team_name)\n",
    "    if team_name == 'rai' and 2016 <= year <= 2019:\n",
    "        return abbreviations_df['Backup_Upper_Reference'].iloc[idx]\n",
    "    elif team_name == 'sdg' and year == 2016:\n",
    "        return abbreviations_df['Backup_Upper_Reference'].iloc[idx]\n",
    "    return abbreviations_df['Upper_Reference'].iloc[idx]\n",
    "\n",
    "def scrape_player_data(url, table_id=None):\n",
    "    \"\"\"Generic function to scrape table data from a URL.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', {'id': table_id}) if table_id else soup.find('table')\n",
    "    return pd.read_html(str(table))[0]\n",
    "\n",
    "def filter_year_data(df, year, upper_name):\n",
    "    \"\"\"Filter DataFrame to the specific year and team.\"\"\"\n",
    "    df['Year'] = df['Year'].apply(lambda x: str(x)[:4] if pd.notna(x) else x)\n",
    "    for i in range(len(df)):\n",
    "        if pd.notna(df.loc[i, 'Year']) and int(df.loc[i, 'Year']) == year:\n",
    "            teams = str(df.loc[i, 'Tm'])\n",
    "            if teams.endswith('TM'):\n",
    "                for x in range(1, int(teams[0]) + 1):\n",
    "                    if str(df.loc[i + x, 'Tm']) == upper_name:\n",
    "                        df.iloc[i, 2:] = df.iloc[i + x, 2:]\n",
    "                        break\n",
    "            return df.loc[[i]].reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping qb information\n",
    "\n",
    "# Scraping single-season statistics for each quarterback\n",
    "def scrape_qb_single_season():\n",
    "    abbreviations_df = pd.read_csv('team_abbreviations_updated.csv')\n",
    "    qb_exceptions = {\n",
    "        6: {2018: 7}, 9: {2020: 7}, 10: {2016: 7, 2021: 7}, 11: {2022: 7},\n",
    "        13: {2021: 7, 2023: 7}, 14: {2022: 7}, 15: {2023: 7}, 18: {2017: 7},\n",
    "        19: {2019: 7}, 20: {2020: 7}, 21: {2018: 7}, 26: {2020: 7},\n",
    "        27: {2019: 7, 2022: 7, 2023: 7}, 29: {2016: 7}\n",
    "    }\n",
    "\n",
    "    for num, team in enumerate(team_hrefs[:32]):\n",
    "        response = requests.get(f\"https://www.pro-football-reference.com/{team}/\")\n",
    "        response.raise_for_status()\n",
    "        time.sleep(5)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        href_list = [a['href'].replace('.htm', '') for a in soup.find_all('a', href=True)]\n",
    "        relevant_hrefs = [href for year in years if f'{team}/{year}' in href_list \n",
    "                          for href in href_list[href_list.index(f'{team}/{year}'):][:9]]\n",
    "\n",
    "        for year in years:\n",
    "            if f'{team}/{year}' not in href_list:\n",
    "                continue\n",
    "            idx = relevant_hrefs.index(f'{team}/{year}')\n",
    "            offset = qb_exceptions.get(num, {}).get(year, 6)\n",
    "            qb_href = relevant_hrefs[idx + offset]\n",
    "\n",
    "            # Scrape QB base stats\n",
    "            qb_base_df = scrape_player_data(f'https://www.pro-football-reference.com{qb_href}.htm')\n",
    "            qb_base_df = qb_base_df.iloc[:-1]\n",
    "            upper_name = get_team_upper_name(team, year, abbreviations_df)\n",
    "            qb_base_df = filter_year_data(qb_base_df, year, upper_name)\n",
    "\n",
    "            columns_to_drop = ['Tm', 'Pos', 'No.', 'GS', 'QBrec', 'Lng', 'Y/A', 'AY/A', 'Y/C', \n",
    "                              'Yds.1', 'NY/A', 'ANY/A', '4QC', 'GWD', 'AV', 'Awards', 'Y/G']\n",
    "            qb_base_df = qb_base_df.drop(columns=[col for col in columns_to_drop if col in qb_base_df.columns])\n",
    "            qb_base_df.columns = ['Year', 'Qb_Age', 'Qb_G', 'Cmp', 'Pass_Att', 'Cmp%', 'Pass_Yds', \n",
    "                                 'Pass_TD', 'TD%', 'Int', 'Rate', 'Sk', '1D_Passing', 'Pass_Succ%']\n",
    "\n",
    "            # Scrape QB rushing stats\n",
    "            time.sleep(5)\n",
    "            qb_rushing_df = scrape_player_data(f'https://www.pro-football-reference.com{qb_href}.htm', \n",
    "                                             'rushing_and_receiving')\n",
    "            qb_rushing_df.columns = qb_rushing_df.columns.droplevel()\n",
    "            qb_rushing_df = filter_year_data(qb_rushing_df, year, upper_name)\n",
    "            qb_rushing_df.columns = [col if i < 7 else f'Qb_{col}' for i, col in enumerate(qb_rushing_df.columns)]\n",
    "            qb_rushing_df = qb_rushing_df.drop(columns=[col for col in qb_rushing_df.columns \n",
    "                                                       if col not in ['Year', 'Qb_Rush_Att', 'Qb_Rush_Yds', \n",
    "                                                                      'Qb_Rush_Td', 'Qb_Rush_1D', 'Qb_Rush_Succ%', \n",
    "                                                                      'Qb_Touches', 'Qb_Fmb']])\n",
    "\n",
    "            # Scrape QB fantasy stats\n",
    "            time.sleep(5)\n",
    "            qb_fantasy_df = scrape_player_data(f'https://www.pro-football-reference.com{qb_href}/fantasy/')\n",
    "            qb_fantasy_df.columns = qb_fantasy_df.columns.droplevel().droplevel()\n",
    "            qb_fantasy_df = qb_fantasy_df.fillna(0)\n",
    "            qb_fantasy_df = filter_year_data(qb_fantasy_df, year, upper_name)\n",
    "            qb_fantasy_df = qb_fantasy_df.iloc[:, [-9, -4]]\n",
    "            qb_fantasy_df.columns = ['Qb_Snap_Percentage', 'Qb_FantPt']\n",
    "            qb_fantasy_df['Qb_Snap_Percentage'] = qb_fantasy_df['Qb_Snap_Percentage'].str.replace('%', '').astype(float) / 100\n",
    "\n",
    "            # Combine and adjust stats\n",
    "            qb_df = pd.concat([qb_base_df, qb_rushing_df.drop('Year', axis=1), qb_fantasy_df], axis=1)\n",
    "            per_game_stats = ['Cmp', 'Pass_Att', 'Pass_TD', 'Pass_Yds', 'Int', '1D_Passing', 'Sk', \n",
    "                             'Qb_Rush_Att', 'Qb_Rush_Yds', 'Qb_Rush_Td', 'Qb_Rush_1D', 'Qb_Touches', \n",
    "                             'Qb_Fmb', 'Qb_FantPt']\n",
    "            games = int(qb_df['Qb_G'].iloc[0])\n",
    "            for stat in per_game_stats:\n",
    "                qb_df[stat] = qb_df[stat].astype(float) / games\n",
    "\n",
    "            # Update main DataFrame\n",
    "            full_df = pd.read_csv('clustered_df.csv')\n",
    "            for r in range(len(full_df)):\n",
    "                if full_df.loc[r, 'team'] == upper_name and full_df.loc[r, 'season'] == year and full_df.loc[r, 'QB_Position'] == 1:\n",
    "                    qb_df.index = [r]\n",
    "                    for col in qb_df.columns:\n",
    "                        full_df.loc[r, col] = qb_df.loc[r, col]\n",
    "            full_df.to_csv('clustered_df_qb_single_season.csv', index=False)\n",
    "            print(f\"{year} quarterback scraped for {team}.\")\n",
    "\n",
    "scrape_qb_single_season()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping positional statistics\n",
    "\n",
    "# Scraping career averages for players\n",
    "def scrape_career_averages(position, hrefs, num_range, filename):\n",
    "    abbreviations_df = pd.read_csv('team_abbreviations_updated.csv')\n",
    "    for num in num_range:\n",
    "        team = team_hrefs[num]\n",
    "        for year in years:\n",
    "            snap_df = scrape_player_data(f'https://www.pro-football-reference.com{team}/{year}-snap-counts.htm', 'snap_counts')\n",
    "            players = [(str(row[0]), str(row[1]), int(row[2]), hrefs[i]) \n",
    "                       for i, row in enumerate(snap_df.itertuples(index=False)) if row[1] == position]\n",
    "            counts = [p[2] for p in players]\n",
    "            max_indices = sorted(range(len(counts)), key=lambda i: counts[i], reverse=True)[:{'QB': 1, 'RB': 2, 'WR': 3, 'TE': 1}[position]]\n",
    "            pos_hrefs = [players[i][3].replace('.htm', '') for i in max_indices]\n",
    "\n",
    "            for i, href in enumerate(pos_hrefs, 1):\n",
    "                if position == 'QB' and href == '/players/H/HillTa00':\n",
    "                    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "                    tables = pd.read_html(f\"https://www.pro-football-reference.com{href}.htm\")\n",
    "                    base_df = tables[2]\n",
    "                else:\n",
    "                    base_df = scrape_player_data(f\"https://www.pro-football-reference.com{href}.htm\", \n",
    "                                               'passing' if position == 'QB' else 'rushing_and_receiving' if position == 'QB' else 'receiving_and_rushing')\n",
    "                \n",
    "                upper_name = get_team_upper_name(team, year, abbreviations_df)\n",
    "                base_df['Year'] = base_df['Year'].apply(lambda x: str(x)[:4] if pd.notna(x) and x != '*' else x)\n",
    "                age = next((int(base_df.loc[i, 'Age']) for i in range(len(base_df)) \n",
    "                           if pd.notna(base_df.loc[i, 'Year']) and int(base_df.loc[i, 'Year']) == year), 0)\n",
    "                career_idx = base_df[base_df['Year'] == 'Career'].index[0]\n",
    "                for x in range(career_idx + 1, len(base_df)):\n",
    "                    if base_df.loc[x, 'Tm'] == upper_name:\n",
    "                        base_df.iloc[career_idx, 1:] = base_df.iloc[x, 1:]\n",
    "                        break\n",
    "                base_df = base_df.loc[[career_idx]].reset_index(drop=True)\n",
    "                base_df.loc[0, 'Age'] = age\n",
    "                base_df.loc[0, 'Year'] = year\n",
    "\n",
    "                # Column renaming and dropping based on position\n",
    "                columns_map = {\n",
    "                    'QB': {'Cmp': 'Qb_Cmp', 'Att': 'Qb_Att', 'Cmp%': 'Qb_Cmp%', 'Yds': 'Qb_Yds', 'TD': 'Qb_Pass_Td', \n",
    "                           'TD%': 'Qb_Td%', 'Int': 'Qb_Int', 'Int%': 'Qb_Int%', '1D': 'Qb_Pass_1D', 'Succ%': 'Qb_Pass_Succ%', \n",
    "                           'Rate': 'Qb_Rate', 'Sk': 'Qb_Sk', 'Sk%': 'Qb_Sk%'},\n",
    "                    'RB': lambda u: {7: f'Rush_Att_{u}', 8: f'Rush_Yds_{u}', 9: f'Rush_Tds_{u}', 10: f'Rush_1D_{u}', \n",
    "                                    11: f'Rush_Succ%_{u}', 16: f'Rb_Tgt_{u}', 17: f'Rb_Rec_{u}', 18: f'Rb_Rec_Yds_{u}', \n",
    "                                    20: f'Rb_Rec_Td_{u}', 21: f'Rb_Rec_1D_{u}', 22: f'Rb_Rec_Succ%_{u}', 28: f'Rb_Touch_{u}', \n",
    "                                    32: f'Rb_Fmb_{u}'},\n",
    "                    'WR': lambda u: {7: f'Rec_Rush_Att_{u}', 8: f'Rec_Rush_Yds_{u}', 9: f'Rec_Rush_Tds_{u}', \n",
    "                                    10: f'Rec_Rush_1D_{u}', 11: f'Rec_Rush_Succ%_{u}', 16: f'Rec_Tgt_{u}', 17: f'Wr_Rec_{u}', \n",
    "                                    18: f'Rec_Yds_{u}', 20: f'Rec_Tds_{u}', 21: f'Rec_1D_{u}', 22: f'Rec_Succ%_{u}', \n",
    "                                    28: f'Rec_Touch_{u}', 32: f'Rec_Fumb_{u}'},\n",
    "                    'TE': {7: 'Te_Rec_Tgt', 8: 'Te_Rec', 9: 'Te_Rec_Yds', 11: 'Te_Rec_Tds', 12: 'Te_Rec_1D', \n",
    "                          13: 'Te_Rec_Succ%', 19: 'Te_Rec_Rush_Att', 20: 'Te_Rec_Rush_Yds', 21: 'Te_Rec_Rush_Tds', \n",
    "                          22: 'Te_Rec_Rush_1D', 23: 'Te_Rec_Rush_Succ%', 28: 'Te_Rec_Touch', 32: 'Te_Rec_Fumb'}\n",
    "                }\n",
    "                drop_cols = {\n",
    "                    'QB': ['Tm', 'Pos', 'No.', 'GS', 'QBrec', 'Lng', 'Y/A', 'AY/A', 'Y/C', 'Yds.1', 'NY/A', 'ANY/A', \n",
    "                          '4QC', 'GWD', 'AV', 'Awards', 'Y/G', 'QBR'],\n",
    "                    'RB': ['Tm', 'Pos', 'No.', 'GS', 'Lng', 'Y/A', 'Y/G', 'Y/R', 'Lng', 'R/G', 'Y/G', 'Ctch%', 'Y/Tgt', \n",
    "                          'Y/Tch', 'YScm', 'RRTD', 'AV', 'A/G', 'Awards'],\n",
    "                    'WR': ['Tm', 'Pos', 'No.', 'GS', 'Lng', 'Y/A', 'Y/G', 'Y/R', 'Lng', 'R/G', 'Y/G', 'Ctch%', 'Y/Tgt', \n",
    "                          'Y/Tch', 'YScm', 'RRTD', 'AV', 'A/G', 'Awards'],\n",
    "                    'TE': ['Tm', 'Pos', 'No.', 'GS', 'Y/R', 'Lng', 'R/G', 'Y/G', 'Ctch%', 'Y/Tgt', 'Lng', 'Y/A', 'Y/G', \n",
    "                          'A/G', 'Y/Tch', 'YScm', 'RRTD', 'AV', 'Awards']\n",
    "                }\n",
    "\n",
    "                if position == 'QB':\n",
    "                    base_df.columns = [columns_map['QB'].get(col, col) for col in base_df.columns]\n",
    "                    if href == '/players/H/HillTa00':\n",
    "                        drop_cols['QB'].remove('AV')\n",
    "                else:\n",
    "                    base_cols = base_df.columns.tolist()\n",
    "                    col_map = columns_map[position](i) if position in ['RB', 'WR'] else columns_map[position]\n",
    "                    base_df.columns = [col_map.get(idx, col) for idx, col in enumerate(base_cols)]\n",
    "                base_df = base_df.drop(columns=[col for col in drop_cols[position] if col in base_df.columns])\n",
    "\n",
    "                if position == 'QB':\n",
    "                    rushing_df = scrape_player_data(f\"https://www.pro-football-reference.com{href}.htm\", \n",
    "                                                  'rushing_and_receiving')\n",
    "                    rushing_df.columns = rushing_df.columns.droplevel()\n",
    "                    rushing_df = filter_year_data(rushing_df, year, upper_name)\n",
    "                    rushing_df.columns = [f'Qb_{col}' if i >= 7 else col for i, col in enumerate(rushing_df.columns)]\n",
    "                    rushing_df = rushing_df.drop(columns=[col for col in rushing_df.columns \n",
    "                                                         if col not in ['Year', 'Qb_Rush_Att', 'Qb_Rush_Yds', \n",
    "                                                                        'Qb_Rush_Td', 'Qb_Rush_1D', 'Qb_Rush_Succ%', \n",
    "                                                                        'Qb_Touches', 'Qb_Fmb']])\n",
    "                    final_df = pd.concat([base_df, rushing_df.drop('Year', axis=1)], axis=1)\n",
    "                else:\n",
    "                    final_df = base_df\n",
    "\n",
    "                final_df.columns = ['Year' if i == 0 else f'{position}_Age' if i == 1 else f'{position}_G' if i == 2 \n",
    "                                   else col for i, col in enumerate(final_df.columns)]\n",
    "                final_df = final_df.fillna(0)\n",
    "\n",
    "                # Update main DataFrame\n",
    "                full_df = pd.read_csv('clustered_df_careers_all_positions.csv')\n",
    "                for r in range(len(full_df)):\n",
    "                    if full_df.loc[r, 'team'] == upper_name and full_df.loc[r, 'season'] == year:\n",
    "                        final_df.index = [r]\n",
    "                        for col in final_df.columns:\n",
    "                            full_df.loc[r, col] = final_df.loc[r, col]\n",
    "                full_df.to_csv(filename, index=False)\n",
    "                print(f\"{year}, {i if position in ['RB', 'WR'] else ''} string {position.lower()} scraped for {team}.\")\n",
    "\n",
    "# Execute career scraping for each position\n",
    "scrape_career_averages('QB', [href for _, href in pd.read_html(requests.get(\n",
    "    f'https://www.pro-football-reference.com{team_hrefs[0]}/{years[0]}-snap-counts.htm'\n",
    ").text)[0].itertuples(index=False) if _[1] == 'QB'], range(32), 'clustered_df_careers_qb.csv')\n",
    "scrape_career_averages('RB', [href for _, href in pd.read_html(requests.get(\n",
    "    f'https://www.pro-football-reference.com{team_hrefs[0]}/{years[0]}-snap-counts.htm'\n",
    ").text)[0].itertuples(index=False) if _[1] == 'RB'], range(30, 32), 'clustered_df_careers_rb.csv')\n",
    "scrape_career_averages('WR', [href for _, href in pd.read_html(requests.get(\n",
    "    f'https://www.pro-football-reference.com{team_hrefs[0]}/{years[0]}-snap-counts.htm'\n",
    ").text)[0].itertuples(index=False) if _[1] == 'WR'], range(30, 32), 'clustered_df_careers_wr.csv')\n",
    "scrape_career_averages('TE', [href for _, href in pd.read_html(requests.get(\n",
    "    f'https://www.pro-football-reference.com{team_hrefs[0]}/{years[0]}-snap-counts.htm'\n",
    ").text)[0].itertuples(index=False) if _[1] == 'TE'], range(31, 32), 'clustered_df_careers_te.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all career statistics to per-game\n",
    "def convert_to_per_game():\n",
    "    df = pd.read_csv('clustered_df_careers_all_positions.csv')\n",
    "    stat_df = pd.read_csv('stats.csv')\n",
    "    stat_groups = {\n",
    "        'QB': (stat_df['Qb_Stats'].tolist(), 'Qb_G'),\n",
    "        'RB_1': (stat_df['Rb_1_Stats'].tolist(), 'Rb_G_1'),\n",
    "        'RB_2': (stat_df['Rb_2_Stats'].tolist(), 'Rb_G_2'),\n",
    "        'WR_1': (stat_df['Wr_1_Stats'].tolist(), 'Wr_G_1'),\n",
    "        'WR_2': (stat_df['Wr_2_Stats'].tolist(), 'Wr_G_2'),\n",
    "        'WR_3': (stat_df['Wr_3_Stats'].tolist(), 'Wr_G_3'),\n",
    "        'TE': (stat_df['Te_Stats'].tolist(), 'Te_G')\n",
    "    }\n",
    "    \n",
    "    for stats, game_col in stat_groups.values():\n",
    "        for col in stats:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(float) / df[game_col].astype(float)\n",
    "    \n",
    "    df.fillna(0).to_csv('career_per_game.csv', index=False)\n",
    "\n",
    "convert_to_per_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting NFL tendency data based on past career average data\n",
    "def predict_nfl_tendencies():\n",
    "    # Load career average data\n",
    "    df = pd.read_csv('career_per_game.csv')\n",
    "    columns = df.columns.tolist()\n",
    "    \n",
    "    # Separate features and targets\n",
    "    target = columns[6:42]  # Assuming these are the tendency-related columns\n",
    "    features = columns[42:]  # Remaining columns as features\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train the RandomForestRegressor\n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and evaluate\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean Squared Error for tendency prediction: {mse}')\n",
    "    \n",
    "    # Predict tendencies for new data\n",
    "    new_df = pd.read_csv('clustered_df_careers_all_positions_2024.csv')\n",
    "    X_new = new_df[features]\n",
    "    predictions = rf_model.predict(X_new)\n",
    "    new_df[target] = predictions\n",
    "    \n",
    "    # Save the updated DataFrame\n",
    "    new_df.to_csv('tendency_predictions_2024.csv', index=False)\n",
    "    print(\"Tendency predictions for 2024 saved to 'tendency_predictions_2024.csv'\")\n",
    "\n",
    "# Training model on QB dataframe with fantasy results\n",
    "def predict_qb_fantasy():\n",
    "    # Load QB single-season data\n",
    "    qb_df = pd.read_csv('clustered_df_qb_single_season.csv')\n",
    "    columns = qb_df.columns.tolist()\n",
    "    \n",
    "    # Define features and target\n",
    "    features = columns[6:43]  # Assuming these are QB-related stats excluding fantasy points\n",
    "    target = 'Qb_FantPt'\n",
    "    \n",
    "    X = qb_df[features]\n",
    "    y = qb_df[target]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train the RandomForestRegressor\n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and evaluate\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean Squared Error for QB fantasy prediction: {mse}')\n",
    "    \n",
    "    # Predict fantasy points for new QB data\n",
    "    new_df = pd.read_csv('qb_fantasy_predictions.csv')\n",
    "    X_new = new_df[features]\n",
    "    predictions = rf_model.predict(X_new)\n",
    "    new_df[target] = predictions\n",
    "    \n",
    "    # Sort by fantasy points and save\n",
    "    new_df = new_df.sort_values(by='Qb_FantPt', ascending=False)\n",
    "    new_df.to_csv('qb_fantasy_predictions_updated.csv', index=False)\n",
    "    print(\"QB fantasy predictions saved to 'qb_fantasy_predictions_updated.csv'\")\n",
    "\n",
    "# Execute prediction functions\n",
    "predict_nfl_tendencies()\n",
    "predict_qb_fantasy()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
